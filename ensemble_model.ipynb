{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nature Conservance Fish Identification Using CNN Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "\n",
    "from glob import iglob\n",
    "from models import Inception, Resnet50,Vgg16BN\n",
    "# from untitled import Vgg16BN\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# ROOT_DIR = os.getcwd()\n",
    "ROOT_DIR = '/nfs/science/shared/ipythonNotebooks/anantk/Kgl/Fish/'\n",
    "\n",
    "# DATA_HOME_DIR = ROOT_DIR + '/data'\n",
    "DATA_HOME_DIR = ROOT_DIR \n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/science/shared/ipythonNotebooks/anantk/Kgl/Fish/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = DATA_HOME_DIR + '/' \n",
    "split_train_path = data_path + '/train_split'\n",
    "full_train_path = data_path + '/train/train/'\n",
    "valid_path = data_path + '/val_split/'\n",
    "test_path = DATA_HOME_DIR + '/test_stg1/'\n",
    "saved_model_path = ROOT_DIR + '/models/'\n",
    "submission_path = ROOT_DIR + '/submissions/'\n",
    "\n",
    "# data\n",
    "batch_size = 16\n",
    "nb_split_train_samples = 3177\n",
    "nb_full_train_samples = 3777\n",
    "nb_valid_samples = 600\n",
    "nb_test_samples = 1000\n",
    "classes = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"NoF\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "nb_classes = len(classes)\n",
    "\n",
    "# model\n",
    "nb_runs = 5\n",
    "nb_epoch = 10\n",
    "nb_aug = 7\n",
    "dropout = 0.0\n",
    "clip = 0.01\n",
    "use_val = False\n",
    "archs = [\"vggbn\"]\n",
    "\n",
    "models = {\n",
    "    \"vggbn\": Vgg16BN(size=(64, 64), n_classes=nb_classes, lr=0.001,\n",
    "                           batch_size=batch_size,dropout=dropout),\n",
    "    \"inception\": Inception(size=(64, 64), n_classes=nb_classes,\n",
    "                           lr=0.001, batch_size=batch_size),\n",
    "    \"resnet\": Resnet50(size=(64, 64), n_classes=nb_classes, lr=0.001,\n",
    "                    batch_size=batch_size, dropout=dropout)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a training loop that runs `nb_runs` times and trains a model for each architecture we've specified. \n",
    "\n",
    "We have the option to use validation data or the full training set -- if we use \n",
    "the former, the best model from each training loop will be saved and the path appended to our `models` list for \n",
    "later use; if the latter, we just save the weights from the last epoch of each training loop, since there's no validation monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(parent_model, model_str):\n",
    "    parent_model.build()    \n",
    "    model_fn = saved_model_path + '{val_loss:.2f}-loss_{epoch}epoch_' + model_str\n",
    "    ckpt = ModelCheckpoint(filepath=model_fn, monitor='val_loss',\n",
    "                           save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    if use_val:\n",
    "        parent_model.fit_val(split_train_path, valid_path, nb_trn_samples=nb_split_train_samples, \n",
    "                             nb_val_samples=nb_valid_samples, nb_epoch=nb_epoch, callbacks=[ckpt], aug=nb_aug)\n",
    "\n",
    "        model_path = max(iglob(saved_model_path + '*.h5'), key=os.path.getctime)\n",
    "        return model_path\n",
    "    \n",
    "    model_fn = saved_model_path + '{}epoch_'.format(nb_epoch) + model_str\n",
    "    parent_model.fit_full(full_train_path, nb_trn_samples=nb_full_train_samples, nb_epoch=nb_epoch, aug=nb_aug)\n",
    "    model = parent_model.model\n",
    "    model.save_weights(model_fn)\n",
    "    del parent_model.model \n",
    "    \n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Run 1 of 5...\n",
      "\n",
      "Training vggbn model...\n",
      "\n",
      "Found 3777 images belonging to 8 classes.\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "def train_all():    \n",
    "    model_paths = {\n",
    "        \"vggbn\": [],\n",
    "        \"inception\": [],\n",
    "        'resnet': [],\n",
    "    }\n",
    "    \n",
    "    for run in range(nb_runs):\n",
    "        print(\"Starting Training Run {0} of {1}...\\n\".format(run+1, nb_runs))\n",
    "        aug_str = \"aug\" if nb_aug else \"no-aug\"\n",
    "        \n",
    "        for arch in archs:\n",
    "            print(\"Training {} model...\\n\".format(arch))\n",
    "            model = models[arch]\n",
    "            model_str = \"{0}x{1}_{2}_{3}lr_run{4}_{5}.h5\".format(model.size[0], model.size[1], aug_str,\n",
    "                                                                 model.lr, run, arch)\n",
    "            model_path = train(model, model_str)\n",
    "            model_paths[arch].append(model_path)\n",
    "        \n",
    "    print(\"Done.\") \n",
    "    return model_paths\n",
    "        \n",
    "model_paths = train_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Prediction Run 1 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 2 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 3 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 4 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 5 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def test(model_paths):    \n",
    "    predictions_full = np.zeros((nb_test_samples, nb_classes))\n",
    "    \n",
    "    for run in range(nb_runs):\n",
    "        print(\"\\nStarting Prediction Run {0} of {1}...\\n\".format(run+1, nb_runs))\n",
    "        predictions_aug = np.zeros((nb_test_samples, nb_classes))\n",
    "        \n",
    "        for aug in range(nb_aug):\n",
    "            print(\"\\n--Predicting on Augmentation {0} of {1}...\\n\".format(aug+1, nb_aug))\n",
    "            predictions_mod = np.zeros((nb_test_samples, nb_classes))\n",
    "            \n",
    "            for arch in archs:\n",
    "                print(\"----Predicting on {} model...\".format(arch))\n",
    "                parent = models[arch]\n",
    "                model = parent.build()\n",
    "                model.load_weights(model_paths[arch][run])\n",
    "                pred, filenames = parent.test(test_path, nb_test_samples, aug=nb_aug)\n",
    "                predictions_mod += pred\n",
    "            \n",
    "            predictions_mod /= len(archs)\n",
    "            predictions_aug += predictions_mod\n",
    "\n",
    "        predictions_aug /= nb_aug\n",
    "        predictions_full += predictions_aug\n",
    "    \n",
    "    predictions_full /= nb_runs\n",
    "    return predictions_full, filenames\n",
    "\n",
    "predictions, filenames = test(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Predictions to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Predictions to CSV...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def write_submission(predictions, filenames):\n",
    "    preds = np.clip(predictions, clip, 1-clip)\n",
    "    sub_fn = submission_path + '{0}epoch_{1}aug_{2}clip_{3}runs'.format(nb_epoch, nb_aug, clip, nb_runs)\n",
    "    \n",
    "    for arch in archs:\n",
    "        sub_fn += \"_{}\".format(arch)\n",
    "\n",
    "    with open(sub_fn + '.csv', 'w') as f:\n",
    "        print(\"Writing Predictions to CSV...\")\n",
    "        f.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
    "        for i, image_name in enumerate(filenames):\n",
    "            pred = ['%.6f' % p for p in preds[i, :]]\n",
    "            f.write('%s,%s\\n' % (os.path.basename(image_name), ','.join(pred)))\n",
    "        print(\"Done.\")\n",
    "\n",
    "write_submission(predictions, filenames)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
