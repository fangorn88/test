{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:22: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:34: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:36: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:65: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    }
   ],
   "source": [
    "from __future__ import  division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "x1 = pd.read_csv('train_features.csv')\n",
    "x2 = pd.read_csv('magicfeat_train.csv')\n",
    "x3 = pd.read_csv('fanokas.csv')\n",
    "x4 = pd.read_csv('owl_feat.csv')\n",
    "x5 = pd.read_csv('jacfeat.csv')\n",
    "\n",
    "col_to_drop = ['z_len1','z_len2','z_word_len1','z_word_len2','z_word_match']\n",
    "\n",
    "x4.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "xf = pd.concat([x1,x2.ix[:,2:],x3.ix[:,1:],x4.ix[:,9:],x5.ix[:,1:]], axis = 1)\n",
    "\n",
    "x1t = pd.read_csv('test_features.csv')\n",
    "x2t = pd.read_csv('magicfeat_test.csv')\n",
    "x3t = pd.read_csv('fanokas_test.csv')\n",
    "x4t = pd.read_csv('owl_feat_test.csv')\n",
    "x5t = pd.read_csv('jacfeat_test.csv')\n",
    "\n",
    "col_to_drop = ['z_len1','z_len2','z_word_len1','z_word_len2','z_word_match']\n",
    "\n",
    "x4t.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "xft = pd.concat([x1t,x2t.ix[:,2:],x3t.ix[:,1:],x4t.ix[:,6:],x5t.ix[:,1:]], axis = 1)\n",
    "\n",
    "X = xf.ix[:,2:]\n",
    "\n",
    "y = X['is_duplicate'].values\n",
    "\n",
    "X.drop('is_duplicate', inplace = True, axis = 1)\n",
    "\n",
    "col_to_drop = ['q1_hash','q2_hash']\n",
    "\n",
    "X.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "# sbtr = np.loadtxt(\"sbenchfeat_tsvd100_train.gz\", delimiter=\",\")\n",
    "rstr = np.loadtxt(\"russ_tr.gz\", delimiter=\",\")\n",
    "rspacetr = np.loadtxt(\"russpacy_tr.gz\", delimiter=\",\")\n",
    "\n",
    "# sbts = np.loadtxt(\"sbenchfeat_tsvd100_test.gz\", delimiter=\",\")\n",
    "rsts = np.loadtxt(\"russ_ts.gz\", delimiter=\",\")\n",
    "rspacets = np.loadtxt(\"russpacy_ts.gz\", delimiter=\",\")\n",
    "\n",
    "\n",
    "magic2tr = np.loadtxt(\"magic2_tr.gz\", delimiter=\",\")\n",
    "magic2ts = np.loadtxt(\"magic2_ts.gz\", delimiter=\",\")\n",
    "\n",
    "magic3tr = np.loadtxt(\"magic3_tr.gz\", delimiter=\",\")\n",
    "magic3ts = np.loadtxt(\"magic3_ts.gz\", delimiter=\",\")\n",
    "\n",
    "# x_train = np.column_stack((np.array(X),rstr[:,0:17],rstr[:,18:20],rspacetr[:,0:3],sbtr,magic2tr,magic3tr))\n",
    "\n",
    "# print x_train.shape\n",
    "\n",
    "xtest = xft.ix[:,2:]\n",
    "\n",
    "col_to_drop = ['q1_hash','q2_hash']\n",
    "xtest.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "# x_test = np.column_stack((np.array(xtest),rsts[:,0:17],rsts[:,18:20],rspacets[:,0:3],sbts,magic2ts,magic3ts))\n",
    "\n",
    "# print x_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbtr = np.loadtxt(\"train_stacker_xgb1.csv\", delimiter=\",\")\n",
    "xgbts = np.loadtxt(\"test_stacker_xgb1.csv\", delimiter=\",\")\n",
    "\n",
    "# lstmtr = np.loadtxt(\"train_stacker_lstm2.csv\", delimiter=\",\")\n",
    "# lstmts = np.loadtxt(\"test_stacker_lstm2.csv\", delimiter=\",\")\n",
    "\n",
    "lstmtr1 = np.loadtxt(\"train_stacker_lstm4.csv\", delimiter=\",\")\n",
    "lstmts1 = np.loadtxt(\"test_stacker_lstm4.csv\", delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1_freq</th>\n",
       "      <th>q2_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404260</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404261</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404262</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404263</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404264</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404265</th>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404266</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404267</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404268</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404269</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404270</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404271</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404272</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404273</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404274</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404275</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404276</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404277</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404278</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404279</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404280</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404281</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404282</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404283</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404284</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        q1_freq  q2_freq\n",
       "0             1        2\n",
       "1             8        3\n",
       "2             2        1\n",
       "3             1        1\n",
       "4             3        1\n",
       "5             1        1\n",
       "6             1        1\n",
       "7             1        1\n",
       "8             2        3\n",
       "9             1        1\n",
       "10            1        1\n",
       "11            1        2\n",
       "12            2        2\n",
       "13            2        3\n",
       "14            8        6\n",
       "15           11       20\n",
       "16            1        1\n",
       "17            1        3\n",
       "18           23       70\n",
       "19            3        1\n",
       "20            1        4\n",
       "21            2        1\n",
       "22            4       15\n",
       "23            1        1\n",
       "24            5        8\n",
       "25            7        2\n",
       "26            6        2\n",
       "27            1        1\n",
       "28           66        1\n",
       "29           11       10\n",
       "...         ...      ...\n",
       "404260        3       70\n",
       "404261        2        3\n",
       "404262        1        2\n",
       "404263        5        1\n",
       "404264        1        1\n",
       "404265       26       19\n",
       "404266        6        5\n",
       "404267        9        5\n",
       "404268        2        1\n",
       "404269        2        5\n",
       "404270        1       31\n",
       "404271        1        1\n",
       "404272       10       11\n",
       "404273        3        1\n",
       "404274        4        4\n",
       "404275        3        1\n",
       "404276       23        7\n",
       "404277        2        1\n",
       "404278        1        8\n",
       "404279        1        1\n",
       "404280        1        1\n",
       "404281       13        6\n",
       "404282       27       26\n",
       "404283        1        1\n",
       "404284        1        1\n",
       "404285        3        3\n",
       "404286       15       15\n",
       "404287        1        1\n",
       "404288        1        1\n",
       "404289        1        1\n",
       "\n",
       "[404290 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.ix[:,4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgtr = pd.read_csv('new_magic_train.csv')\n",
    "mgts = pd.read_csv('new_magic_test.csv')                \n",
    "\n",
    "pgtr = pd.read_csv('pagerank_train.csv')\n",
    "pgts = pd.read_csv('pagerank_test.csv')                \n",
    "\n",
    "# mgts.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_tr = np.array(range(0,x_train.shape[0]))\n",
    "# id_ts = np.array(range(0,x_test.shape[0]))\n",
    "\n",
    "xgb_metatr = np.loadtxt(\"2train_stacker_xgb3.gz\", delimiter=\",\")\n",
    "xgb_metats = np.loadtxt(\"2test_stacker_xgb3.gz\", delimiter=\",\")\n",
    "\n",
    "lbm_metatr = np.loadtxt(\"2train_stacker_lgbm1.gz\", delimiter=\",\")\n",
    "lbm_metats = np.loadtxt(\"2test_stacker_lgbm1.gz\", delimiter=\",\")\n",
    "\n",
    "nn_metatr = np.array(pd.read_csv('2train_stacker_nnlight.csv'))\n",
    "nn_metats = np.loadtxt(\"2test_stacker_nnlight.csv\", delimiter=\",\")\n",
    "\n",
    "\n",
    "# id_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 39)\n",
      "(2345796, 39)\n"
     ]
    }
   ],
   "source": [
    "# nntr = np.array(pd.read_csv('train_stacker.csv'))\n",
    "# nnts = np.loadtxt(\"test_stacker_nn1.csv\", delimiter=\",\")\n",
    "\n",
    "# rftr = np.loadtxt(\"train_stacker_rf1.csv\", delimiter=\",\")\n",
    "# rfts = np.loadtxt(\"test_stacker_rf1.csv\", delimiter=\",\")\n",
    "\n",
    "# lrtr = np.loadtxt(\"train_stacker_lr1.csv\", delimiter=\",\")\n",
    "# lrts = np.loadtxt(\"test_stacker_lr1.csv\", delimiter=\",\")\n",
    "\n",
    "# nntr1 = np.array(pd.read_csv('train_stacker_nn2.csv'))\n",
    "# nnts1 = np.loadtxt(\"test_stacker_nn2.csv\", delimiter=\",\")\n",
    "\n",
    "# glvtr = np.loadtxt(\"train_stacker_glv1.csv\", delimiter=\",\")\n",
    "# glvts = np.loadtxt(\"test_stacker_glv1.csv\", delimiter=\",\")\n",
    "\n",
    "# lstmtr2 = np.loadtxt(\"train_stacker_lstm4t.csv\", delimiter=\",\")\n",
    "# lstmts2 = np.loadtxt(\"test_stacker_lstm4t.csv\", delimiter=\",\")\n",
    "\n",
    "# sgtr = np.loadtxt(\"train_stacker_sgd1.csv\", delimiter=\",\")\n",
    "# sgts = np.loadtxt(\"test_stacker_sgd1.csv\", delimiter=\",\")\n",
    "\n",
    "# lbmtr = np.loadtxt(\"train_stacker_lgbm1.csv\", delimiter=\",\")\n",
    "# lbmts = np.loadtxt(\"test_stacker_lgbm1.csv\", delimiter=\",\")\n",
    "\n",
    "# sbenchtr = np.loadtxt(\"train_stacker_sbench1.csv\", delimiter=\",\")\n",
    "# sbenchts = np.loadtxt(\"test_stacker_sbench1.csv\", delimiter=\",\")\n",
    "\n",
    "# sbtr1 = np.loadtxt(\"train_stacker_sbench2.gz\", delimiter=\",\")\n",
    "# sbts1 = np.loadtxt(\"test_stacker_sbench2.gz\", delimiter=\",\")\n",
    "\n",
    "# sbtr2 = np.loadtxt(\"train_stacker_sbench3.gz\", delimiter=\",\")\n",
    "# sbts2 = np.loadtxt(\"test_stacker_sbench3.gz\", delimiter=\",\")\n",
    "\n",
    "# contr = np.loadtxt(\"train_stacker_conv2.gz\", delimiter=\",\")\n",
    "# conts = np.loadtxt(\"test_stacker_conv2.gz\", delimiter=\",\")\n",
    "\n",
    "# xgbtr1 = np.loadtxt(\"train_stacker_xgn1.csv\", delimiter=\",\")\n",
    "# xgbts1 = np.loadtxt(\"test_stacker_xgn1.csv\", delimiter=\",\")\n",
    "\n",
    "# nlp_tr = np.loadtxt(\"lstm_feat_train1.gz\",  delimiter=\",\" )\n",
    "# nlp_ts = np.loadtxt(\"lstm_feat_test1.gz\",  delimiter=\",\")\n",
    "\n",
    "# lstmtr3 = np.loadtxt(\"train_stacker_lstm4t2.gz\", delimiter=\",\")\n",
    "# lstmts3 = np.loadtxt(\"test_stacker_lstm4t2.gz\", delimiter=\",\")\n",
    "\n",
    "# nntr3 = np.array(pd.read_csv('train_stacker_nn3n.csv'))\n",
    "# nnts3 = np.loadtxt(\"test_stacker_nn3n.csv\", delimiter=\",\")\n",
    "\n",
    "# rftr1 = np.loadtxt(\"train_stacker_rf2.csv\", delimiter=\",\")\n",
    "# rfts1 = np.loadtxt(\"test_stacker_rf2.csv\", delimiter=\",\")\n",
    "\n",
    "# lbmtr1 = np.loadtxt(\"train_stacker_lgbm3.csv\", delimiter=\",\")\n",
    "# lbmts1 = np.loadtxt(\"test_stacker_lgbm3.csv\", delimiter=\",\")\n",
    "\n",
    "# nntr4 = np.array(pd.read_csv('train_stacker_nn4n.csv'))\n",
    "# nnts4 = np.loadtxt(\"test_stacker_nn4n.csv\", delimiter=\",\")\n",
    "\n",
    "# lrtr1 = np.loadtxt(\"train_stacker_lr3.csv\", delimiter=\",\")\n",
    "# lrts1 = np.loadtxt(\"test_stacker_lr3.csv\", delimiter=\",\")\n",
    "\n",
    "# owltr = np.loadtxt(\"train_stacker_xgbowl1.csv\", delimiter=\",\")\n",
    "# owlts = np.loadtxt(\"test_stacker_xgbowl1.csv\", delimiter=\",\")\n",
    "\n",
    "# lstmtr4 = np.loadtxt(\"train_stacker_lstm5t.gz\", delimiter=\",\")\n",
    "# lstmts4 = np.loadtxt(\"test_stacker_lstm5t.gz\", delimiter=\",\")\n",
    "\n",
    "# sbxgtr = np.loadtxt(\"train_stacker_sbxgb.gz\", delimiter=\",\")\n",
    "# sbxgts = np.loadtxt(\"test_stacker_sbxgb.gz\", delimiter=\",\")\n",
    "\n",
    "# aqtr = np.loadtxt(\"train_stacker_aqnet.gz\", delimiter=\",\")\n",
    "# aqts = np.loadtxt(\"test_stacker_aqnet.gz\", delimiter=\",\")\n",
    "\n",
    "# svdtr = np.loadtxt(\"train_stacker_nlpsvd.gz\", delimiter=\",\")\n",
    "# svdts = np.loadtxt(\"test_stacker_nlpsvd.gz\", delimiter=\",\")\n",
    "\n",
    "# svxgtr = np.loadtxt(\"train_stacker_svdxg.gz\", delimiter=\",\")\n",
    "# svxgts = np.loadtxt(\"test_stacker_svdxg.gz\", delimiter=\",\")\n",
    "\n",
    "# sbxgtr1 = np.loadtxt(\"train_stacker_sbxgb1.gz\", delimiter=\",\")\n",
    "# sbxgts1 = np.loadtxt(\"test_stacker_sbxgb1.gz\", delimiter=\",\")\n",
    "\n",
    "# rsooftr1 = np.loadtxt(\"train_russoof_1.gz\", delimiter=\",\")\n",
    "# rsoofts1 = np.loadtxt(\"test_russoof_1.gz\", delimiter=\",\")\n",
    "\n",
    "# rsooftr2 = np.loadtxt(\"train_russoof_2.gz\", delimiter=\",\")\n",
    "# rsoofts2 = np.loadtxt(\"test_russoof_2.gz\", delimiter=\",\")\n",
    "\n",
    "# rsooftr3 = np.loadtxt(\"train_russoof_3.gz\", delimiter=\",\")\n",
    "# rsoofts3 = np.loadtxt(\"test_russoof_3.gz\", delimiter=\",\")\n",
    "\n",
    "# rsooftr4 = np.loadtxt(\"train_russoof_4.gz\", delimiter=\",\")\n",
    "# rsoofts4 = np.loadtxt(\"test_russoof_4.gz\", delimiter=\",\")\n",
    "\n",
    "# rsooftr5 = np.loadtxt(\"train_russoof_5.gz\", delimiter=\",\")\n",
    "# rsoofts5 = np.loadtxt(\"test_russoof_5.gz\", delimiter=\",\")\n",
    "\n",
    "# rsooftr6 = np.loadtxt(\"train_russoof_6.gz\", delimiter=\",\")\n",
    "# rsoofts6 = np.loadtxt(\"test_russoof_6.gz\", delimiter=\",\")\n",
    "\n",
    "# x_train = np.column_stack((np.array(X),rstr[:,0:17],rstr[:,18:20],rspacetr[:,0:3],lbmtr,xgbtr1,contr,sbenchtr,sbtr1,\n",
    "#                            sbtr2,xgb_metatr,lbm_metatr,nn_metatr,lstmtr3,svdtr,pgtr,mgtr.iloc[:,2],\n",
    "#                           xgbtr,nntr,lstmtr1,nntr1,sgtr,glvtr,lstmtr2,lrtr,rftr,nntr3,lstmtr4,aqtr,owltr,magic2tr,magic3tr,\n",
    "#                           rftr1,nntr4,lbmtr1,lrtr1,svxgtr,sbxgtr1,rsooftr1,rsooftr2,rsooftr3,rsooftr4,rsooftr5,rsooftr6))\n",
    "\n",
    "# x_test = np.column_stack((np.array(xtest),rsts[:,0:17],rsts[:,18:20],rspacets[:,0:3],lbmts,xgbts1,conts,sbenchts,sbts1,\n",
    "#                           sbts2,xgb_metats,lbm_metats,nn_metats,lstmts3,svdts,pgts,mgts.iloc[:,2],\n",
    "#                           xgbts,nnts,lstmts1,nnts1,sgts,glvts,lstmts2,lrts,rfts,nnts3,lstmts4,aqts,owlts,magic2ts,magic3ts,\n",
    "#                           rfts1,nnts4,lbmts1,lrts1,svxgts,sbxgts1,rsoofts1,rsoofts2,rsoofts3,rsoofts4,rsoofts5,rsoofts6))\n",
    "\n",
    "x_train = np.column_stack((sbenchtr,lbmtr,xgbtr1,contr,sbtr1,sbtr2,xgb_metatr,lbm_metatr,nn_metatr,lstmtr3,svdtr,\n",
    "                          xgbtr,nntr,lstmtr1,nntr1,sgtr,glvtr,lstmtr2,lrtr,rftr,nntr3,lstmtr4,aqtr,owltr,magic2tr,magic3tr,\n",
    "                          rftr1,nntr4,lbmtr1,lrtr1,svxgtr,sbxgtr1,rsooftr1,rsooftr2,rsooftr3,rsooftr4,rsooftr5,rsooftr6))\n",
    "\n",
    "x_test = np.column_stack((sbenchts,lbmts,xgbts1,conts,sbts1,sbts2,xgb_metats,lbm_metats,nn_metats,lstmts3,svdts,\n",
    "                          xgbts,nnts,lstmts1,nnts1,sgts,glvts,lstmts2,lrts,rfts,nnts3,lstmts4,aqts,owlts,magic2ts,magic3ts,\n",
    "                          rfts1,nnts4,lbmts1,lrts1,svxgts,sbxgts1,rsoofts1,rsoofts2,rsoofts3,rsoofts4,rsoofts5,rsoofts6))\n",
    "\n",
    "\n",
    "# owltr,magic2tr,magic3tr,,owlts,magic2ts,magic3ts\n",
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"3train_feat.gz\", x_train, delimiter=\",\", fmt='%.6f')\n",
    "\n",
    "np.savetxt(\"3test_feat.gz\", x_test, delimiter=\",\", fmt='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "Oversampling started for proportion: 0.369026565089\n",
      "Oversampling done, new proportion: 0.191259632688\n",
      "Oversampling started for proportion: 0.369883004774\n",
      "Oversampling done, new proportion: 0.191181170815\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "[0]\ttrain-logloss:0.689043\tvalid-logloss:0.689035\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.418635\tvalid-logloss:0.418548\n",
      "[200]\ttrain-logloss:0.291971\tvalid-logloss:0.292245\n",
      "[300]\ttrain-logloss:0.22568\tvalid-logloss:0.226458\n",
      "[400]\ttrain-logloss:0.189308\tvalid-logloss:0.190572\n",
      "[500]\ttrain-logloss:0.168819\tvalid-logloss:0.17054\n",
      "[600]\ttrain-logloss:0.157087\tvalid-logloss:0.159222\n",
      "[700]\ttrain-logloss:0.150284\tvalid-logloss:0.152816\n",
      "[800]\ttrain-logloss:0.146267\tvalid-logloss:0.14915\n",
      "[900]\ttrain-logloss:0.143849\tvalid-logloss:0.147038\n",
      "[1000]\ttrain-logloss:0.142358\tvalid-logloss:0.145811\n",
      "[1100]\ttrain-logloss:0.141396\tvalid-logloss:0.145104\n",
      "[1200]\ttrain-logloss:0.140746\tvalid-logloss:0.144694\n",
      "[1300]\ttrain-logloss:0.140245\tvalid-logloss:0.144446\n",
      "[1400]\ttrain-logloss:0.139813\tvalid-logloss:0.144284\n",
      "[1500]\ttrain-logloss:0.139427\tvalid-logloss:0.14417\n",
      "[1600]\ttrain-logloss:0.13909\tvalid-logloss:0.144094\n",
      "[1700]\ttrain-logloss:0.138789\tvalid-logloss:0.14404\n",
      "[1800]\ttrain-logloss:0.1385\tvalid-logloss:0.143998\n",
      "[1900]\ttrain-logloss:0.138193\tvalid-logloss:0.143968\n",
      "[2000]\ttrain-logloss:0.137839\tvalid-logloss:0.143947\n",
      "[2100]\ttrain-logloss:0.137489\tvalid-logloss:0.14393\n",
      "Stopping. Best iteration:\n",
      "[2162]\ttrain-logloss:0.137272\tvalid-logloss:0.143916\n",
      "\n",
      "[0.14391627739692278]\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "Oversampling started for proportion: 0.368834871008\n",
      "Oversampling done, new proportion: 0.191277675158\n",
      "Oversampling started for proportion: 0.370649781098\n",
      "Oversampling done, new proportion: 0.191112046372\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "[0]\ttrain-logloss:0.68904\tvalid-logloss:0.689043\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.418667\tvalid-logloss:0.419043\n",
      "[200]\ttrain-logloss:0.292024\tvalid-logloss:0.292719\n",
      "[300]\ttrain-logloss:0.225803\tvalid-logloss:0.226776\n",
      "[400]\ttrain-logloss:0.18945\tvalid-logloss:0.190657\n",
      "[500]\ttrain-logloss:0.168986\tvalid-logloss:0.170413\n",
      "[600]\ttrain-logloss:0.157278\tvalid-logloss:0.158901\n",
      "[700]\ttrain-logloss:0.15051\tvalid-logloss:0.152299\n",
      "[800]\ttrain-logloss:0.146528\tvalid-logloss:0.148477\n",
      "[900]\ttrain-logloss:0.144143\tvalid-logloss:0.146244\n",
      "[1000]\ttrain-logloss:0.142665\tvalid-logloss:0.144928\n",
      "[1100]\ttrain-logloss:0.141723\tvalid-logloss:0.144133\n",
      "[1200]\ttrain-logloss:0.141073\tvalid-logloss:0.143661\n",
      "[1300]\ttrain-logloss:0.140572\tvalid-logloss:0.143372\n",
      "[1400]\ttrain-logloss:0.140144\tvalid-logloss:0.143186\n",
      "[1500]\ttrain-logloss:0.139794\tvalid-logloss:0.143058\n",
      "[1600]\ttrain-logloss:0.139465\tvalid-logloss:0.142978\n",
      "[1700]\ttrain-logloss:0.139161\tvalid-logloss:0.142921\n",
      "[1800]\ttrain-logloss:0.138873\tvalid-logloss:0.142887\n",
      "[1900]\ttrain-logloss:0.138557\tvalid-logloss:0.142851\n",
      "[2000]\ttrain-logloss:0.138209\tvalid-logloss:0.142822\n",
      "[2100]\ttrain-logloss:0.137858\tvalid-logloss:0.142805\n",
      "[2200]\ttrain-logloss:0.137505\tvalid-logloss:0.142794\n",
      "Stopping. Best iteration:\n",
      "[2194]\ttrain-logloss:0.137523\tvalid-logloss:0.142793\n",
      "\n",
      "[0.14391627739692278, 0.14279261886167632]\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "Oversampling started for proportion: 0.369363575651\n",
      "Oversampling done, new proportion: 0.191228070175\n",
      "Oversampling started for proportion: 0.368534962527\n",
      "Oversampling done, new proportion: 0.191306190054\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "[0]\ttrain-logloss:0.689039\tvalid-logloss:0.689047\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.418605\tvalid-logloss:0.419323\n",
      "[200]\ttrain-logloss:0.291931\tvalid-logloss:0.293241\n",
      "[300]\ttrain-logloss:0.225666\tvalid-logloss:0.227416\n",
      "[400]\ttrain-logloss:0.18932\tvalid-logloss:0.191368\n",
      "[500]\ttrain-logloss:0.168851\tvalid-logloss:0.171114\n",
      "[600]\ttrain-logloss:0.157153\tvalid-logloss:0.159577\n",
      "[700]\ttrain-logloss:0.150399\tvalid-logloss:0.152947\n",
      "[800]\ttrain-logloss:0.146418\tvalid-logloss:0.149071\n",
      "[900]\ttrain-logloss:0.144032\tvalid-logloss:0.146794\n",
      "[1000]\ttrain-logloss:0.142556\tvalid-logloss:0.14544\n",
      "[1100]\ttrain-logloss:0.141605\tvalid-logloss:0.144621\n",
      "[1200]\ttrain-logloss:0.140959\tvalid-logloss:0.144115\n",
      "[1300]\ttrain-logloss:0.140461\tvalid-logloss:0.143808\n",
      "[1400]\ttrain-logloss:0.140036\tvalid-logloss:0.143594\n",
      "[1500]\ttrain-logloss:0.139653\tvalid-logloss:0.14345\n",
      "[1600]\ttrain-logloss:0.139334\tvalid-logloss:0.14336\n",
      "[1700]\ttrain-logloss:0.139038\tvalid-logloss:0.14329\n",
      "[1800]\ttrain-logloss:0.138761\tvalid-logloss:0.143249\n",
      "[1900]\ttrain-logloss:0.138446\tvalid-logloss:0.143208\n",
      "[2000]\ttrain-logloss:0.13808\tvalid-logloss:0.143169\n",
      "[2100]\ttrain-logloss:0.137743\tvalid-logloss:0.143141\n",
      "[2200]\ttrain-logloss:0.137399\tvalid-logloss:0.143119\n",
      "[2300]\ttrain-logloss:0.137048\tvalid-logloss:0.143092\n",
      "[2400]\ttrain-logloss:0.136695\tvalid-logloss:0.143073\n",
      "Stopping. Best iteration:\n",
      "[2424]\ttrain-logloss:0.136607\tvalid-logloss:0.143065\n",
      "\n",
      "[0.14391627739692278, 0.14279261886167632, 0.14306534977084132]\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "Oversampling started for proportion: 0.369338840931\n",
      "Oversampling done, new proportion: 0.191230569741\n",
      "Oversampling started for proportion: 0.368633901407\n",
      "Oversampling done, new proportion: 0.191297371883\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "[0]\ttrain-logloss:0.689038\tvalid-logloss:0.689055\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.418522\tvalid-logloss:0.419875\n",
      "[200]\ttrain-logloss:0.291849\tvalid-logloss:0.293868\n",
      "[300]\ttrain-logloss:0.225558\tvalid-logloss:0.228049\n",
      "[400]\ttrain-logloss:0.18916\tvalid-logloss:0.192011\n",
      "[500]\ttrain-logloss:0.168673\tvalid-logloss:0.171792\n",
      "[600]\ttrain-logloss:0.15695\tvalid-logloss:0.16029\n",
      "[700]\ttrain-logloss:0.150173\tvalid-logloss:0.153694\n",
      "[800]\ttrain-logloss:0.146176\tvalid-logloss:0.149881\n",
      "[900]\ttrain-logloss:0.143772\tvalid-logloss:0.147652\n",
      "[1000]\ttrain-logloss:0.142293\tvalid-logloss:0.146343\n",
      "[1100]\ttrain-logloss:0.141334\tvalid-logloss:0.145571\n",
      "[1200]\ttrain-logloss:0.140678\tvalid-logloss:0.145104\n",
      "[1300]\ttrain-logloss:0.14018\tvalid-logloss:0.144807\n",
      "[1400]\ttrain-logloss:0.139749\tvalid-logloss:0.144608\n",
      "[1500]\ttrain-logloss:0.139366\tvalid-logloss:0.144475\n",
      "[1600]\ttrain-logloss:0.139039\tvalid-logloss:0.144383\n",
      "[1700]\ttrain-logloss:0.138737\tvalid-logloss:0.144312\n",
      "[1800]\ttrain-logloss:0.138435\tvalid-logloss:0.144272\n",
      "[1900]\ttrain-logloss:0.138098\tvalid-logloss:0.144238\n",
      "[2000]\ttrain-logloss:0.137747\tvalid-logloss:0.144201\n",
      "[2100]\ttrain-logloss:0.137392\tvalid-logloss:0.144176\n",
      "[2200]\ttrain-logloss:0.137057\tvalid-logloss:0.144154\n",
      "[2300]\ttrain-logloss:0.136717\tvalid-logloss:0.144131\n",
      "Stopping. Best iteration:\n",
      "[2361]\ttrain-logloss:0.136508\tvalid-logloss:0.144117\n",
      "\n",
      "[0.14391627739692278, 0.14279261886167632, 0.14306534977084132, 0.14411677432469638]\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "Oversampling started for proportion: 0.369425412451\n",
      "Oversampling done, new proportion: 0.191222435076\n",
      "Oversampling started for proportion: 0.368287615326\n",
      "Oversampling done, new proportion: 0.1913301037\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "[0]\ttrain-logloss:0.689042\tvalid-logloss:0.689041\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.418723\tvalid-logloss:0.418776\n",
      "[200]\ttrain-logloss:0.29212\tvalid-logloss:0.292333\n",
      "[300]\ttrain-logloss:0.225896\tvalid-logloss:0.22635\n",
      "[400]\ttrain-logloss:0.189549\tvalid-logloss:0.19025\n",
      "[500]\ttrain-logloss:0.169092\tvalid-logloss:0.170032\n",
      "[600]\ttrain-logloss:0.157388\tvalid-logloss:0.158553\n",
      "[700]\ttrain-logloss:0.150618\tvalid-logloss:0.151976\n",
      "[800]\ttrain-logloss:0.146611\tvalid-logloss:0.148175\n",
      "[900]\ttrain-logloss:0.144202\tvalid-logloss:0.145967\n",
      "[1000]\ttrain-logloss:0.142714\tvalid-logloss:0.144664\n",
      "[1100]\ttrain-logloss:0.141754\tvalid-logloss:0.14389\n",
      "[1200]\ttrain-logloss:0.141103\tvalid-logloss:0.143433\n",
      "[1300]\ttrain-logloss:0.140594\tvalid-logloss:0.143154\n",
      "[1400]\ttrain-logloss:0.140162\tvalid-logloss:0.142973\n",
      "[1500]\ttrain-logloss:0.139778\tvalid-logloss:0.142857\n",
      "[1600]\ttrain-logloss:0.139436\tvalid-logloss:0.142771\n",
      "[1700]\ttrain-logloss:0.139116\tvalid-logloss:0.142723\n",
      "[1800]\ttrain-logloss:0.138803\tvalid-logloss:0.142688\n",
      "[1900]\ttrain-logloss:0.138475\tvalid-logloss:0.142664\n",
      "Stopping. Best iteration:\n",
      "[1961]\ttrain-logloss:0.138247\tvalid-logloss:0.142649\n",
      "\n",
      "[0.14391627739692278, 0.14279261886167632, 0.14306534977084132, 0.14411677432469638, 0.14264905895808197]\n"
     ]
    }
   ],
   "source": [
    "RS = 2016\n",
    "ROUNDS = 400\n",
    "\n",
    "print(\"Started\")\n",
    "np.random.seed(RS)\n",
    "input_folder = ''\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.005\n",
    "params['max_depth'] = 6\n",
    "params['seed'] = RS\n",
    "# params['gamma'] = 5\n",
    "params['subsample'] = 0.95\n",
    "params['colsample_bytree'] = 0.75\n",
    "params['min_child_weight'] = 10\n",
    "params['reg_alpha'] = 2\n",
    "# params['reg_lambda'] = 2\n",
    "params['n_jobs'] = 32\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "y_train = np.array(y)\n",
    "\n",
    "train_stacker=[ [0.0 for s in range(1)]  for k in range (0,(x_train.shape[0])) ]\n",
    "\n",
    "cv_scores = []\n",
    "oof_preds = []\n",
    "a = [0 for x in range(2345796)]\n",
    "# StratifiedKFold\n",
    "# kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=RS)\n",
    "# for dev_index, val_index in kf.split(range(x_train.shape[0]),y_train):\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(x_train.shape[0])):\n",
    "        dev_X, val_X = x_train[dev_index,:], x_train[val_index,:]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "        \n",
    "        pos_train = dev_X[dev_y == 1]\n",
    "        neg_train = dev_X[dev_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xd = np.concatenate((pos_train, neg_train))\n",
    "        yd = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        pos_train = val_X[val_y == 1]\n",
    "        neg_train = val_X[val_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xv = np.concatenate((pos_train, neg_train))\n",
    "        yv = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "\n",
    "        d_train = xgb.DMatrix(Xd, label=yd)\n",
    "        d_valid = xgb.DMatrix(Xv, label=yv)\n",
    "\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        bst = xgb.train(params, d_train, 5000, watchlist, early_stopping_rounds=25, verbose_eval=100)\n",
    "        # ntree_limit=model.best_ntree_limit\n",
    "        preds = bst.predict(d_valid, ntree_limit=bst.best_ntree_limit)\n",
    "        cv_scores.append(log_loss(yv, preds))\n",
    "        print(cv_scores)\n",
    "#         break\n",
    "        \n",
    "        d_test = xgb.DMatrix(x_test)\n",
    "        preds_tr = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "        a = np.column_stack((a,preds_tr))\n",
    "\n",
    "        d_valorg = xgb.DMatrix(val_X, label=val_y)\n",
    "        predsorg = bst.predict(d_valorg, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "#         predictions = preds.reshape(-1,1)\n",
    "        no=0\n",
    "        for real_index in val_index:\n",
    "            for d in range (0,1):\n",
    "                train_stacker[real_index][d]=(predsorg[no])\n",
    "            no+=1\n",
    "\n",
    "# b = pd.DataFrame(a)\n",
    "# b['sum'] = b.sum(axis = 1)/5\n",
    "\n",
    "# sub = pd.DataFrame()\n",
    "# sub['test_id'] = x4t['test_id']\n",
    "# sub['is_duplicate'] = b['sum']\n",
    "# sub.to_csv(\"xgb_stack_16.csv\", index=False)\n",
    "# [0.14679638005158449, 0.14643568394088646, 0.14695301106657524, 0.14738008193419261, 0.14605956315322077]\n",
    "# [0.14629926832710563, 0.14606952289254052, 0.14638265721616533, 0.14687541244637101, 0.14573516873536307]\n",
    "# [0.14655595844865862, 0.14596795960342543, 0.14643300162670578]\n",
    "# [0.14655595844865862, 0.14596795960342543, 0.14643300162670578, 0.1472989982452006, 0.1460610474228651]\n",
    "# [0.14681656791503989, 0.14627290312044094, 0.14712146834967574, 0.14773910422640363, 0.14630592158639893]\n",
    "# [0.14639234763909087, 0.14569616587687539, 0.14647693750567869, 0.1470194202825103, 0.14583537522827511]\n",
    "# [0.14633978851522797, 0.14547056343098994, 0.1462774578658336, 0.14666908841973081, 0.14591071212086731]\n",
    "# [0.14604253466505532, 0.14526491434032673, 0.14594325619907694, 0.14651440185039458, 0.14559316344188111]\n",
    "# [0.14617171795151768, 0.14555889283206599, 0.14620601573073846, 0.14679953331829179, 0.14573525765371792]\n",
    "\n",
    "# [0.14605396414966829, 0.14552495830927542, 0.14597708259252917, 0.14655229686031751, 0.1453054463522597]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = pd.DataFrame(a)\n",
    "\n",
    "b['sum'] = b.sum(axis = 1)/5\n",
    "# [0.14600727370188754, 0.14544825295074776, 0.14596532675096102, 0.14650781185934783, 0.14528044902433937]\n",
    "# [0.14607445705137667, 0.14547740551268393, 0.14587153345507556, 0.14642157045202223, 0.1452241104178662]\n",
    "# [0.1459919657664169, 0.1454384662685565, 0.14583130137423958, 0.14653725802725331, 0.14523262817425422]\n",
    "# [0.14594534065203074, 0.14540613940843813, 0.14575943927277321, 0.14645383820660426, 0.14524890892410494]\n",
    "# [0.14597443603330801, 0.14480043444652063, 0.14525341818071591, 0.14604332789310262, 0.14481647042907519]\n",
    "# [0.14592741293875855, 0.1446144748158234, 0.14505227943520599, 0.14599320073826713, 0.14470319974679161]\n",
    "# [0.14563385252705296, 0.14461794367881492, 0.14475958050019688, 0.14593929909917952, 0.14451138835557784]\n",
    "# [0.14561401066422744, 0.14434587350455086, 0.14469600766340365, 0.14577312842825135, 0.14447393471245529]\n",
    "# [0.1445950168279444, 0.14398874044809273, 0.14453248459062426, 0.14515394631723633, 0.14366273762810131]\n",
    "# [0.14422273607572852, 0.14306190447034878, 0.14320179686051809, 0.14447022824303118, 0.14265517230783645]\n",
    "# [0.14402145142521824, 0.14292811676006567, 0.14314733916378442, 0.14422494220235443, 0.14261435321214111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = x4t['test_id']\n",
    "sub['is_duplicate'] = b['sum']\n",
    "sub.to_csv(\"xgb_stack_18.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323431, 39)\n",
      "(80859, 39)\n",
      "[0]\ttrain-logloss:0.689336\tvalid-logloss:0.689346\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.438562\tvalid-logloss:0.439317\n",
      "[200]\ttrain-logloss:0.32133\tvalid-logloss:0.32267\n",
      "[300]\ttrain-logloss:0.260185\tvalid-logloss:0.262062\n",
      "[400]\ttrain-logloss:0.226738\tvalid-logloss:0.22906\n",
      "[500]\ttrain-logloss:0.207964\tvalid-logloss:0.210652\n",
      "[600]\ttrain-logloss:0.197231\tvalid-logloss:0.200218\n",
      "[700]\ttrain-logloss:0.190991\tvalid-logloss:0.194238\n",
      "[800]\ttrain-logloss:0.187278\tvalid-logloss:0.190755\n",
      "[900]\ttrain-logloss:0.185014\tvalid-logloss:0.188693\n",
      "[1000]\ttrain-logloss:0.183605\tvalid-logloss:0.187474\n",
      "[1100]\ttrain-logloss:0.182692\tvalid-logloss:0.18674\n",
      "[1200]\ttrain-logloss:0.182069\tvalid-logloss:0.186287\n",
      "[1300]\ttrain-logloss:0.181598\tvalid-logloss:0.185984\n",
      "[1400]\ttrain-logloss:0.181227\tvalid-logloss:0.185786\n",
      "[1500]\ttrain-logloss:0.180877\tvalid-logloss:0.185647\n",
      "[1600]\ttrain-logloss:0.180529\tvalid-logloss:0.185524\n",
      "[1700]\ttrain-logloss:0.180166\tvalid-logloss:0.185444\n",
      "[1800]\ttrain-logloss:0.17976\tvalid-logloss:0.185367\n",
      "[1900]\ttrain-logloss:0.179364\tvalid-logloss:0.185298\n",
      "[2000]\ttrain-logloss:0.178924\tvalid-logloss:0.185227\n",
      "[2100]\ttrain-logloss:0.178557\tvalid-logloss:0.185178\n",
      "[2200]\ttrain-logloss:0.178133\tvalid-logloss:0.185127\n",
      "[2300]\ttrain-logloss:0.177759\tvalid-logloss:0.185092\n",
      "[2400]\ttrain-logloss:0.177396\tvalid-logloss:0.185064\n",
      "[2500]\ttrain-logloss:0.177045\tvalid-logloss:0.185029\n",
      "[2600]\ttrain-logloss:0.176692\tvalid-logloss:0.185011\n",
      "[2700]\ttrain-logloss:0.176368\tvalid-logloss:0.184987\n",
      "Stopping. Best iteration:\n",
      "[2730]\ttrain-logloss:0.176262\tvalid-logloss:0.184978\n",
      "\n",
      "[0.18497809959394468]\n",
      "(323431, 39)\n",
      "(80859, 39)\n",
      "[0]\ttrain-logloss:0.689338\tvalid-logloss:0.689337\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.438768\tvalid-logloss:0.438766\n",
      "[200]\ttrain-logloss:0.321651\tvalid-logloss:0.321737\n",
      "[300]\ttrain-logloss:0.260593\tvalid-logloss:0.26081\n",
      "[400]\ttrain-logloss:0.227195\tvalid-logloss:0.22758\n",
      "[500]\ttrain-logloss:0.208451\tvalid-logloss:0.208982\n",
      "[600]\ttrain-logloss:0.197746\tvalid-logloss:0.198398\n",
      "[700]\ttrain-logloss:0.191508\tvalid-logloss:0.192293\n",
      "[800]\ttrain-logloss:0.18781\tvalid-logloss:0.18874\n",
      "[900]\ttrain-logloss:0.185553\tvalid-logloss:0.186643\n",
      "[1000]\ttrain-logloss:0.184139\tvalid-logloss:0.18539\n",
      "[1100]\ttrain-logloss:0.18322\tvalid-logloss:0.184626\n",
      "[1200]\ttrain-logloss:0.182583\tvalid-logloss:0.184144\n",
      "[1300]\ttrain-logloss:0.182113\tvalid-logloss:0.183842\n",
      "[1400]\ttrain-logloss:0.181723\tvalid-logloss:0.183629\n",
      "[1500]\ttrain-logloss:0.18135\tvalid-logloss:0.183489\n",
      "[1600]\ttrain-logloss:0.180997\tvalid-logloss:0.183384\n",
      "[1700]\ttrain-logloss:0.18062\tvalid-logloss:0.183297\n",
      "[1800]\ttrain-logloss:0.180199\tvalid-logloss:0.183224\n",
      "[1900]\ttrain-logloss:0.179761\tvalid-logloss:0.183161\n",
      "[2000]\ttrain-logloss:0.179364\tvalid-logloss:0.183111\n",
      "[2100]\ttrain-logloss:0.178973\tvalid-logloss:0.183068\n",
      "[2200]\ttrain-logloss:0.178614\tvalid-logloss:0.183038\n",
      "[2300]\ttrain-logloss:0.178244\tvalid-logloss:0.183006\n",
      "[2400]\ttrain-logloss:0.177853\tvalid-logloss:0.18298\n",
      "[2500]\ttrain-logloss:0.177498\tvalid-logloss:0.182961\n",
      "[2600]\ttrain-logloss:0.177136\tvalid-logloss:0.182945\n",
      "Stopping. Best iteration:\n",
      "[2632]\ttrain-logloss:0.177015\tvalid-logloss:0.182936\n",
      "\n",
      "[0.18497809959394468, 0.18293647198493149]\n",
      "(323432, 39)\n",
      "(80858, 39)\n",
      "[0]\ttrain-logloss:0.689346\tvalid-logloss:0.689348\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.438711\tvalid-logloss:0.438924\n",
      "[200]\ttrain-logloss:0.321606\tvalid-logloss:0.322024\n",
      "[300]\ttrain-logloss:0.26054\tvalid-logloss:0.261161\n",
      "[400]\ttrain-logloss:0.227114\tvalid-logloss:0.227932\n",
      "[500]\ttrain-logloss:0.208352\tvalid-logloss:0.20932\n",
      "[600]\ttrain-logloss:0.197642\tvalid-logloss:0.19874\n",
      "[700]\ttrain-logloss:0.191413\tvalid-logloss:0.192648\n",
      "[800]\ttrain-logloss:0.187702\tvalid-logloss:0.18907\n",
      "[900]\ttrain-logloss:0.185454\tvalid-logloss:0.186955\n",
      "[1000]\ttrain-logloss:0.184054\tvalid-logloss:0.185698\n",
      "[1100]\ttrain-logloss:0.183148\tvalid-logloss:0.18493\n",
      "[1200]\ttrain-logloss:0.182521\tvalid-logloss:0.184448\n",
      "[1300]\ttrain-logloss:0.18205\tvalid-logloss:0.184144\n",
      "[1400]\ttrain-logloss:0.181664\tvalid-logloss:0.183925\n",
      "[1500]\ttrain-logloss:0.181313\tvalid-logloss:0.183775\n",
      "[1600]\ttrain-logloss:0.180957\tvalid-logloss:0.183661\n",
      "[1700]\ttrain-logloss:0.180594\tvalid-logloss:0.183578\n",
      "[1800]\ttrain-logloss:0.180177\tvalid-logloss:0.183497\n",
      "[1900]\ttrain-logloss:0.17979\tvalid-logloss:0.183439\n",
      "[2000]\ttrain-logloss:0.179383\tvalid-logloss:0.183371\n",
      "[2100]\ttrain-logloss:0.178994\tvalid-logloss:0.183313\n",
      "[2200]\ttrain-logloss:0.178614\tvalid-logloss:0.183264\n",
      "[2300]\ttrain-logloss:0.178224\tvalid-logloss:0.183216\n",
      "[2400]\ttrain-logloss:0.177861\tvalid-logloss:0.183182\n",
      "[2500]\ttrain-logloss:0.177516\tvalid-logloss:0.183138\n",
      "[2600]\ttrain-logloss:0.177171\tvalid-logloss:0.183103\n",
      "[2700]\ttrain-logloss:0.176807\tvalid-logloss:0.183083\n",
      "[2800]\ttrain-logloss:0.176494\tvalid-logloss:0.183055\n",
      "[2900]\ttrain-logloss:0.17616\tvalid-logloss:0.18303\n",
      "[3000]\ttrain-logloss:0.175834\tvalid-logloss:0.183008\n",
      "[3100]\ttrain-logloss:0.175518\tvalid-logloss:0.182984\n",
      "Stopping. Best iteration:\n",
      "[3095]\ttrain-logloss:0.175534\tvalid-logloss:0.182982\n",
      "\n",
      "[0.18497809959394468, 0.18293647198493149, 0.18298195269226639]\n",
      "(323433, 39)\n",
      "(80857, 39)\n",
      "[0]\ttrain-logloss:0.689337\tvalid-logloss:0.689345\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.43858\tvalid-logloss:0.439206\n",
      "[200]\ttrain-logloss:0.3214\tvalid-logloss:0.322544\n",
      "[300]\ttrain-logloss:0.260243\tvalid-logloss:0.26188\n",
      "[400]\ttrain-logloss:0.226783\tvalid-logloss:0.228828\n",
      "[500]\ttrain-logloss:0.207958\tvalid-logloss:0.210375\n",
      "[600]\ttrain-logloss:0.197209\tvalid-logloss:0.199943\n",
      "[700]\ttrain-logloss:0.190967\tvalid-logloss:0.193964\n",
      "[800]\ttrain-logloss:0.187258\tvalid-logloss:0.190489\n",
      "[900]\ttrain-logloss:0.185005\tvalid-logloss:0.188455\n",
      "[1000]\ttrain-logloss:0.1836\tvalid-logloss:0.187253\n",
      "[1100]\ttrain-logloss:0.182681\tvalid-logloss:0.18652\n",
      "[1200]\ttrain-logloss:0.182045\tvalid-logloss:0.186058\n",
      "[1300]\ttrain-logloss:0.181578\tvalid-logloss:0.185768\n",
      "[1400]\ttrain-logloss:0.181203\tvalid-logloss:0.185577\n",
      "[1500]\ttrain-logloss:0.180851\tvalid-logloss:0.185441\n",
      "[1600]\ttrain-logloss:0.180496\tvalid-logloss:0.185331\n",
      "[1700]\ttrain-logloss:0.180142\tvalid-logloss:0.18526\n",
      "[1800]\ttrain-logloss:0.179763\tvalid-logloss:0.185191\n",
      "[1900]\ttrain-logloss:0.179368\tvalid-logloss:0.185131\n",
      "[2000]\ttrain-logloss:0.178969\tvalid-logloss:0.185086\n",
      "[2100]\ttrain-logloss:0.178589\tvalid-logloss:0.185054\n",
      "[2200]\ttrain-logloss:0.178237\tvalid-logloss:0.185022\n",
      "[2300]\ttrain-logloss:0.177853\tvalid-logloss:0.184993\n",
      "[2400]\ttrain-logloss:0.177493\tvalid-logloss:0.184971\n",
      "Stopping. Best iteration:\n",
      "[2463]\ttrain-logloss:0.177284\tvalid-logloss:0.184953\n",
      "\n",
      "[0.18497809959394468, 0.18293647198493149, 0.18298195269226639, 0.18495317948940171]\n",
      "(323433, 39)\n",
      "(80857, 39)\n",
      "[0]\ttrain-logloss:0.689333\tvalid-logloss:0.689341\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.438492\tvalid-logloss:0.439195\n",
      "[200]\ttrain-logloss:0.321271\tvalid-logloss:0.322659\n",
      "[300]\ttrain-logloss:0.260111\tvalid-logloss:0.262124\n",
      "[400]\ttrain-logloss:0.226643\tvalid-logloss:0.229193\n",
      "[500]\ttrain-logloss:0.207822\tvalid-logloss:0.2108\n",
      "[600]\ttrain-logloss:0.197084\tvalid-logloss:0.200429\n",
      "[700]\ttrain-logloss:0.190839\tvalid-logloss:0.194468\n",
      "[800]\ttrain-logloss:0.187137\tvalid-logloss:0.191022\n",
      "[900]\ttrain-logloss:0.184882\tvalid-logloss:0.188989\n",
      "[1000]\ttrain-logloss:0.183479\tvalid-logloss:0.187786\n",
      "[1100]\ttrain-logloss:0.182573\tvalid-logloss:0.187062\n",
      "[1200]\ttrain-logloss:0.181932\tvalid-logloss:0.186609\n",
      "[1300]\ttrain-logloss:0.181456\tvalid-logloss:0.186322\n",
      "[1400]\ttrain-logloss:0.181074\tvalid-logloss:0.186132\n",
      "[1500]\ttrain-logloss:0.180709\tvalid-logloss:0.185991\n",
      "[1600]\ttrain-logloss:0.180381\tvalid-logloss:0.185894\n",
      "[1700]\ttrain-logloss:0.180001\tvalid-logloss:0.185804\n",
      "[1800]\ttrain-logloss:0.179619\tvalid-logloss:0.185743\n",
      "[1900]\ttrain-logloss:0.179202\tvalid-logloss:0.185677\n",
      "[2000]\ttrain-logloss:0.178801\tvalid-logloss:0.185621\n",
      "[2100]\ttrain-logloss:0.178442\tvalid-logloss:0.185579\n",
      "[2200]\ttrain-logloss:0.178051\tvalid-logloss:0.185549\n",
      "[2300]\ttrain-logloss:0.177683\tvalid-logloss:0.185514\n",
      "[2400]\ttrain-logloss:0.177325\tvalid-logloss:0.185488\n",
      "[2500]\ttrain-logloss:0.176966\tvalid-logloss:0.185464\n",
      "[2600]\ttrain-logloss:0.176609\tvalid-logloss:0.185436\n",
      "Stopping. Best iteration:\n",
      "[2576]\ttrain-logloss:0.176696\tvalid-logloss:0.185436\n",
      "\n",
      "[0.18497809959394468, 0.18293647198493149, 0.18298195269226639, 0.18495317948940171, 0.18543627972969226]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "y_train = np.array(y)\n",
    "\n",
    "train_stacker=[ [0.0 for s in range(1)]  for k in range (0,(x_train.shape[0])) ]\n",
    "\n",
    "cv_scores = []\n",
    "oof_preds = []\n",
    "a = [0 for x in range(2345796)]\n",
    "# StratifiedKFold\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(x_train.shape[0]),y_train):\n",
    "# kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "# for dev_index, val_index in kf.split(range(x_train.shape[0])):\n",
    "        dev_X, val_X = x_train[dev_index,:], x_train[val_index,:]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "\n",
    "        d_train = xgb.DMatrix(dev_X, label=dev_y)\n",
    "        d_valid = xgb.DMatrix(val_X, label=val_y)\n",
    "\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        bst = xgb.train(params, d_train, 5000, watchlist, early_stopping_rounds=25, verbose_eval=100)\n",
    "        # ntree_limit=model.best_ntree_limit\n",
    "        preds = bst.predict(d_valid, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "\n",
    "        print(cv_scores)\n",
    "#         break\n",
    "        \n",
    "        d_test = xgb.DMatrix(x_test)\n",
    "        ptr = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "        \n",
    "        m = 0.1742 / 0.369 \n",
    "        n = (1 - 0.1742) / (1 - 0.369)\n",
    "\n",
    "        preds_tr = m * ptr / (m * ptr + n * (1 - ptr))\n",
    "\n",
    "        a = np.column_stack((a,preds_tr))\n",
    "\n",
    "        no=0\n",
    "        for real_index in val_index:\n",
    "            for d in range (0,1):\n",
    "                train_stacker[real_index][d]=(preds[no])\n",
    "            no+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [0.18880335309362842, 0.18801828370599291, 0.18785027919053612, 0.18894454006251779, 0.18767936468008359]\n",
    "# [0.18868942190684651, 0.18696706128012827, 0.18663978014219634, 0.18821848688990747, 0.18666975335206612]\n",
    "# [0.18844793317579234, 0.18679252873047139, 0.18617363049655314, 0.18787651645561473, 0.18658128432138549]\n",
    "# [0.18836814453853373, 0.18666654678319805, 0.18611280448351419, 0.18785123997003758, 0.18637769772650983]\n",
    "# [0.18692333977020642, 0.18571598922110646, 0.18574369308099167, 0.18692709768084501, 0.18537371455293869]\n",
    "# [0.18653777996241505, 0.18444821738266107, 0.18413882199040532, 0.18570046653557878, 0.18392717849489101]\n",
    "b1 = pd.DataFrame(a)\n",
    "\n",
    "b1['sum'] = b1.sum(axis = 1)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = pd.DataFrame(a)\n",
    "\n",
    "b1['sum'] = b1.sum(axis = 1)/5\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = x4t['test_id']\n",
    "sub['is_duplicate'] = b1['sum']\n",
    "sub.to_csv(\"xgb_stack_24.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471830985915\n",
      "1.30913126189\n"
     ]
    }
   ],
   "source": [
    "a = 0.1742 / 0.369 \n",
    "b = (1 - 0.1742) / (1 - 0.369)\n",
    "print a \n",
    "print b \n",
    "function to convert is f(x) = a * x / (a * x + b * (1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"2train_stacker_xgb3.gz\", train_stacker, delimiter=\",\", fmt='%.6f')\n",
    "\n",
    "np.savetxt(\"2test_stacker_xgb3.gz\", np.array(b['sum']), delimiter=\",\", fmt='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAacCAYAAAA8aQniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBmpJkiSpBAO1JEmSVIKBWpIkSSrh/wCAzGpM/mvVhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12580d350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 30.0)\n",
    "xgb.plot_importance(bst); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "# 'metric': 'binary_logloss', 'num_boost_round' :1000,\n",
    "t4_params = {\n",
    "    'boosting_type': 'gbdt', 'objective': 'binary', 'nthread': 12, 'silent': True,\n",
    "    'num_leaves': 2**6, 'learning_rate': 0.01, 'max_depth': 9,\n",
    "    'max_bin': 255, 'subsample_for_bin': 50000,\n",
    "    'subsample': 0.85, 'subsample_freq': 1, 'colsample_bytree': 0.80, 'reg_alpha':2, 'reg_lambda':0,\n",
    "    'min_split_gain': 0.5, 'min_child_weight': 10, 'min_child_samples': 2, 'scale_pos_weight': 1}\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Oversampling started for proportion: 0.369026565089\n",
      "Oversampling done, new proportion: 0.191259632688\n",
      "Oversampling started for proportion: 0.369883004774\n",
      "Oversampling done, new proportion: 0.191181170815\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[25]\tvalid_0's binary_logloss: 0.529309\n",
      "[50]\tvalid_0's binary_logloss: 0.421919\n",
      "[75]\tvalid_0's binary_logloss: 0.348029\n",
      "[100]\tvalid_0's binary_logloss: 0.295514\n",
      "[125]\tvalid_0's binary_logloss: 0.257549\n",
      "[150]\tvalid_0's binary_logloss: 0.229721\n",
      "[175]\tvalid_0's binary_logloss: 0.209094\n",
      "[200]\tvalid_0's binary_logloss: 0.193698\n",
      "[225]\tvalid_0's binary_logloss: 0.182185\n",
      "[250]\tvalid_0's binary_logloss: 0.173518\n",
      "[275]\tvalid_0's binary_logloss: 0.166979\n",
      "[300]\tvalid_0's binary_logloss: 0.162031\n",
      "[325]\tvalid_0's binary_logloss: 0.158285\n",
      "[350]\tvalid_0's binary_logloss: 0.155435\n",
      "[375]\tvalid_0's binary_logloss: 0.153247\n",
      "[400]\tvalid_0's binary_logloss: 0.151574\n",
      "[425]\tvalid_0's binary_logloss: 0.150292\n",
      "[450]\tvalid_0's binary_logloss: 0.149325\n",
      "[475]\tvalid_0's binary_logloss: 0.148574\n",
      "[500]\tvalid_0's binary_logloss: 0.147989\n",
      "[525]\tvalid_0's binary_logloss: 0.147537\n",
      "[550]\tvalid_0's binary_logloss: 0.147186\n",
      "[575]\tvalid_0's binary_logloss: 0.146917\n",
      "[600]\tvalid_0's binary_logloss: 0.146691\n",
      "[625]\tvalid_0's binary_logloss: 0.146529\n",
      "[650]\tvalid_0's binary_logloss: 0.146396\n",
      "[675]\tvalid_0's binary_logloss: 0.146305\n",
      "[700]\tvalid_0's binary_logloss: 0.146232\n",
      "[725]\tvalid_0's binary_logloss: 0.146153\n",
      "[750]\tvalid_0's binary_logloss: 0.146104\n",
      "[775]\tvalid_0's binary_logloss: 0.146066\n",
      "[800]\tvalid_0's binary_logloss: 0.146026\n",
      "[825]\tvalid_0's binary_logloss: 0.146\n",
      "[850]\tvalid_0's binary_logloss: 0.14598\n",
      "[875]\tvalid_0's binary_logloss: 0.145959\n",
      "[900]\tvalid_0's binary_logloss: 0.145931\n",
      "[925]\tvalid_0's binary_logloss: 0.145906\n",
      "[950]\tvalid_0's binary_logloss: 0.145892\n",
      "[975]\tvalid_0's binary_logloss: 0.145871\n",
      "[1000]\tvalid_0's binary_logloss: 0.145864\n",
      "Early stopping, best iteration is:\n",
      "[996]\tvalid_0's binary_logloss: 0.145861\n",
      "[0.14585931865495047]\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Oversampling started for proportion: 0.368834871008\n",
      "Oversampling done, new proportion: 0.191277675158\n",
      "Oversampling started for proportion: 0.370649781098\n",
      "Oversampling done, new proportion: 0.191112046372\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[25]\tvalid_0's binary_logloss: 0.529554\n",
      "[50]\tvalid_0's binary_logloss: 0.422256\n",
      "[75]\tvalid_0's binary_logloss: 0.348357\n",
      "[100]\tvalid_0's binary_logloss: 0.295824\n",
      "[125]\tvalid_0's binary_logloss: 0.257791\n",
      "[150]\tvalid_0's binary_logloss: 0.229869\n",
      "[175]\tvalid_0's binary_logloss: 0.209175\n",
      "[200]\tvalid_0's binary_logloss: 0.193736\n",
      "[225]\tvalid_0's binary_logloss: 0.182161\n",
      "[250]\tvalid_0's binary_logloss: 0.173425\n",
      "[275]\tvalid_0's binary_logloss: 0.166816\n",
      "[300]\tvalid_0's binary_logloss: 0.161808\n",
      "[325]\tvalid_0's binary_logloss: 0.157991\n",
      "[350]\tvalid_0's binary_logloss: 0.155069\n",
      "[375]\tvalid_0's binary_logloss: 0.15285\n",
      "[400]\tvalid_0's binary_logloss: 0.151129\n",
      "[425]\tvalid_0's binary_logloss: 0.14982\n",
      "[450]\tvalid_0's binary_logloss: 0.148812\n",
      "[475]\tvalid_0's binary_logloss: 0.148033\n",
      "[500]\tvalid_0's binary_logloss: 0.147427\n",
      "[525]\tvalid_0's binary_logloss: 0.146956\n",
      "[550]\tvalid_0's binary_logloss: 0.146589\n",
      "[575]\tvalid_0's binary_logloss: 0.146302\n",
      "[600]\tvalid_0's binary_logloss: 0.14607\n",
      "[625]\tvalid_0's binary_logloss: 0.1459\n",
      "[650]\tvalid_0's binary_logloss: 0.145759\n",
      "[675]\tvalid_0's binary_logloss: 0.145639\n",
      "[700]\tvalid_0's binary_logloss: 0.145525\n",
      "[725]\tvalid_0's binary_logloss: 0.145453\n",
      "[750]\tvalid_0's binary_logloss: 0.145395\n",
      "[775]\tvalid_0's binary_logloss: 0.145334\n",
      "[800]\tvalid_0's binary_logloss: 0.145291\n",
      "[825]\tvalid_0's binary_logloss: 0.145262\n",
      "[850]\tvalid_0's binary_logloss: 0.145223\n",
      "[875]\tvalid_0's binary_logloss: 0.14518\n",
      "[900]\tvalid_0's binary_logloss: 0.145156\n",
      "Early stopping, best iteration is:\n",
      "[910]\tvalid_0's binary_logloss: 0.145143\n",
      "[0.14585931865495047, 0.14513869774766125]\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Oversampling started for proportion: 0.369363575651\n",
      "Oversampling done, new proportion: 0.191228070175\n",
      "Oversampling started for proportion: 0.368534962527\n",
      "Oversampling done, new proportion: 0.191306190054\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[25]\tvalid_0's binary_logloss: 0.529748\n",
      "[50]\tvalid_0's binary_logloss: 0.422598\n",
      "[75]\tvalid_0's binary_logloss: 0.348792\n",
      "[100]\tvalid_0's binary_logloss: 0.2964\n",
      "[125]\tvalid_0's binary_logloss: 0.258447\n",
      "[150]\tvalid_0's binary_logloss: 0.230575\n",
      "[175]\tvalid_0's binary_logloss: 0.209912\n",
      "[200]\tvalid_0's binary_logloss: 0.194501\n",
      "[225]\tvalid_0's binary_logloss: 0.182919\n",
      "[250]\tvalid_0's binary_logloss: 0.17418\n",
      "[275]\tvalid_0's binary_logloss: 0.167584\n",
      "[300]\tvalid_0's binary_logloss: 0.16258\n",
      "[325]\tvalid_0's binary_logloss: 0.158776\n",
      "[350]\tvalid_0's binary_logloss: 0.15587\n",
      "[375]\tvalid_0's binary_logloss: 0.153636\n",
      "[400]\tvalid_0's binary_logloss: 0.15192\n",
      "[425]\tvalid_0's binary_logloss: 0.150592\n",
      "[450]\tvalid_0's binary_logloss: 0.149586\n",
      "[475]\tvalid_0's binary_logloss: 0.148792\n",
      "[500]\tvalid_0's binary_logloss: 0.148161\n",
      "[525]\tvalid_0's binary_logloss: 0.147687\n",
      "[550]\tvalid_0's binary_logloss: 0.147315\n",
      "[575]\tvalid_0's binary_logloss: 0.147047\n",
      "[600]\tvalid_0's binary_logloss: 0.146828\n",
      "[625]\tvalid_0's binary_logloss: 0.146651\n",
      "[650]\tvalid_0's binary_logloss: 0.146509\n",
      "[675]\tvalid_0's binary_logloss: 0.146398\n",
      "[700]\tvalid_0's binary_logloss: 0.146304\n",
      "[725]\tvalid_0's binary_logloss: 0.146229\n",
      "[750]\tvalid_0's binary_logloss: 0.146179\n",
      "[775]\tvalid_0's binary_logloss: 0.14613\n",
      "[800]\tvalid_0's binary_logloss: 0.146095\n",
      "[825]\tvalid_0's binary_logloss: 0.146063\n",
      "[850]\tvalid_0's binary_logloss: 0.146039\n",
      "[875]\tvalid_0's binary_logloss: 0.146013\n",
      "[900]\tvalid_0's binary_logloss: 0.146001\n",
      "[925]\tvalid_0's binary_logloss: 0.14599\n",
      "Early stopping, best iteration is:\n",
      "[930]\tvalid_0's binary_logloss: 0.145985\n",
      "[0.14585931865495047, 0.14513869774766125, 0.14598420087428199]\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Oversampling started for proportion: 0.369338840931\n",
      "Oversampling done, new proportion: 0.191230569741\n",
      "Oversampling started for proportion: 0.368633901407\n",
      "Oversampling done, new proportion: 0.191297371883\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[25]\tvalid_0's binary_logloss: 0.530026\n",
      "[50]\tvalid_0's binary_logloss: 0.423058\n",
      "[75]\tvalid_0's binary_logloss: 0.349392\n",
      "[100]\tvalid_0's binary_logloss: 0.296985\n",
      "[125]\tvalid_0's binary_logloss: 0.259035\n",
      "[150]\tvalid_0's binary_logloss: 0.231162\n",
      "[175]\tvalid_0's binary_logloss: 0.210479\n",
      "[200]\tvalid_0's binary_logloss: 0.195006\n",
      "[225]\tvalid_0's binary_logloss: 0.183386\n",
      "[250]\tvalid_0's binary_logloss: 0.174622\n",
      "[275]\tvalid_0's binary_logloss: 0.167958\n",
      "[300]\tvalid_0's binary_logloss: 0.162922\n",
      "[325]\tvalid_0's binary_logloss: 0.159095\n",
      "[350]\tvalid_0's binary_logloss: 0.156171\n",
      "[375]\tvalid_0's binary_logloss: 0.153935\n",
      "[400]\tvalid_0's binary_logloss: 0.152205\n",
      "[425]\tvalid_0's binary_logloss: 0.150882\n",
      "[450]\tvalid_0's binary_logloss: 0.149872\n",
      "[475]\tvalid_0's binary_logloss: 0.149092\n",
      "[500]\tvalid_0's binary_logloss: 0.148489\n",
      "[525]\tvalid_0's binary_logloss: 0.148011\n",
      "[550]\tvalid_0's binary_logloss: 0.147662\n",
      "[575]\tvalid_0's binary_logloss: 0.147382\n",
      "[600]\tvalid_0's binary_logloss: 0.147168\n",
      "[625]\tvalid_0's binary_logloss: 0.146989\n",
      "[650]\tvalid_0's binary_logloss: 0.146851\n",
      "[675]\tvalid_0's binary_logloss: 0.146744\n",
      "[700]\tvalid_0's binary_logloss: 0.146644\n",
      "[725]\tvalid_0's binary_logloss: 0.146585\n",
      "[750]\tvalid_0's binary_logloss: 0.146534\n",
      "[775]\tvalid_0's binary_logloss: 0.146492\n",
      "[800]\tvalid_0's binary_logloss: 0.146458\n",
      "[825]\tvalid_0's binary_logloss: 0.146428\n",
      "[850]\tvalid_0's binary_logloss: 0.146402\n",
      "[875]\tvalid_0's binary_logloss: 0.146366\n",
      "[900]\tvalid_0's binary_logloss: 0.14635\n",
      "[925]\tvalid_0's binary_logloss: 0.146338\n",
      "Early stopping, best iteration is:\n",
      "[938]\tvalid_0's binary_logloss: 0.146331\n",
      "[0.14585931865495047, 0.14513869774766125, 0.14598420087428199, 0.14633415314566084]\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Oversampling started for proportion: 0.369425412451\n",
      "Oversampling done, new proportion: 0.191222435076\n",
      "Oversampling started for proportion: 0.368287615326\n",
      "Oversampling done, new proportion: 0.1913301037\n",
      "(323432, 129)\n",
      "(80858, 129)\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[25]\tvalid_0's binary_logloss: 0.529639\n",
      "[50]\tvalid_0's binary_logloss: 0.422435\n",
      "[75]\tvalid_0's binary_logloss: 0.348511\n",
      "[100]\tvalid_0's binary_logloss: 0.296029\n",
      "[125]\tvalid_0's binary_logloss: 0.257989\n",
      "[150]\tvalid_0's binary_logloss: 0.230049\n",
      "[175]\tvalid_0's binary_logloss: 0.209315\n",
      "[200]\tvalid_0's binary_logloss: 0.193825\n",
      "[225]\tvalid_0's binary_logloss: 0.182217\n",
      "[250]\tvalid_0's binary_logloss: 0.17345\n",
      "[275]\tvalid_0's binary_logloss: 0.166817\n",
      "[300]\tvalid_0's binary_logloss: 0.161794\n",
      "[325]\tvalid_0's binary_logloss: 0.157987\n",
      "[350]\tvalid_0's binary_logloss: 0.15509\n",
      "[375]\tvalid_0's binary_logloss: 0.152875\n",
      "[400]\tvalid_0's binary_logloss: 0.151185\n",
      "[425]\tvalid_0's binary_logloss: 0.149883\n",
      "[450]\tvalid_0's binary_logloss: 0.148894\n",
      "[475]\tvalid_0's binary_logloss: 0.148124\n",
      "[500]\tvalid_0's binary_logloss: 0.14753\n",
      "[525]\tvalid_0's binary_logloss: 0.147071\n",
      "[550]\tvalid_0's binary_logloss: 0.146726\n",
      "[575]\tvalid_0's binary_logloss: 0.14646\n",
      "[600]\tvalid_0's binary_logloss: 0.146246\n",
      "[625]\tvalid_0's binary_logloss: 0.146073\n",
      "[650]\tvalid_0's binary_logloss: 0.14594\n",
      "[675]\tvalid_0's binary_logloss: 0.145842\n",
      "[700]\tvalid_0's binary_logloss: 0.145751\n",
      "[725]\tvalid_0's binary_logloss: 0.145691\n",
      "[750]\tvalid_0's binary_logloss: 0.145634\n",
      "[775]\tvalid_0's binary_logloss: 0.145596\n",
      "[800]\tvalid_0's binary_logloss: 0.145563\n",
      "[825]\tvalid_0's binary_logloss: 0.14554\n",
      "[850]\tvalid_0's binary_logloss: 0.145523\n",
      "[875]\tvalid_0's binary_logloss: 0.145508\n",
      "[900]\tvalid_0's binary_logloss: 0.145494\n",
      "[925]\tvalid_0's binary_logloss: 0.14548\n",
      "Early stopping, best iteration is:\n",
      "[917]\tvalid_0's binary_logloss: 0.145474\n",
      "[0.14585931865495047, 0.14513869774766125, 0.14598420087428199, 0.14633415314566084, 0.14547970488812589]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y)\n",
    "\n",
    "train_stacker=[ [0.0 for s in range(1)]  for k in range (0,(x_train.shape[0])) ]\n",
    "\n",
    "cv_scores = []\n",
    "oof_preds = []\n",
    "a = [0 for x in range(2345796)]\n",
    "# StratifiedKFold\n",
    "# kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=RS)\n",
    "# for dev_index, val_index in kf.split(range(x_train.shape[0]),y_train):\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(x_train.shape[0])):\n",
    "        dev_X, val_X = x_train[dev_index,:], x_train[val_index,:]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "        \n",
    "        pos_train = dev_X[dev_y == 1]\n",
    "        neg_train = dev_X[dev_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xd = np.concatenate((pos_train, neg_train))\n",
    "        yd = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        pos_train = val_X[val_y == 1]\n",
    "        neg_train = val_X[val_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xv = np.concatenate((pos_train, neg_train))\n",
    "        yv = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "\n",
    "        t4 = lgbm.sklearn.LGBMClassifier(n_estimators=2000, seed=2016, **t4_params)\n",
    "        bst = t4.fit(Xd, yd, \n",
    "                       eval_set = [(Xv,yv)], eval_metric = 'logloss',early_stopping_rounds = 10, verbose =25) \n",
    "\n",
    "        preds = bst.predict_proba(Xv)\n",
    "        cv_scores.append(log_loss(yv, preds))\n",
    "\n",
    "        preds_tr = bst.predict_proba(x_test)\n",
    "\n",
    "        a = np.column_stack((a,preds_tr[:,1]))\n",
    "        print(cv_scores)\n",
    "\n",
    "        predsorg = bst.predict_proba(val_X)\n",
    "\n",
    "#         predictions = preds.reshape(-1,1)\n",
    "        no=0\n",
    "        for real_index in val_index:\n",
    "            for d in range (0,1):\n",
    "                train_stacker[real_index][d]=(predsorg[no][1])\n",
    "            no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [0.14679638005158449, 0.14643568394088646, 0.14695301106657524, 0.14738008193419261, 0.14605956315322077]\n",
    "# [0.14629926832710563, 0.14606952289254052, 0.14638265721616533, 0.14687541244637101, 0.14573516873536307]\n",
    "# [0.1465937463512855, 0.14615366345193292, 0.1469229977170145, 0.14700542733023864, 0.14592327833231394]\n",
    "# [0.14649405106690855, 0.14572850580037036, 0.14629378735040441, 0.14684076261763193, 0.1458625600681798]\n",
    "# [0.14624227752384916, 0.14531761174638433, 0.14617043566238161, 0.14673412477280165, 0.14583243903690568]\n",
    "# [0.14605673551927814, 0.14523948561000133, 0.14612940352463299, 0.14646254496931341, 0.14563881964088651]\n",
    "b = pd.DataFrame(a)\n",
    "b['sum'] = b.sum(axis = 1)/5\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = x4t['test_id']\n",
    "sub['is_duplicate'] = b['sum']\n",
    "sub.to_csv(\"lgbm_stack_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"2train_stacker_lgbm1.gz\", train_stacker, delimiter=\",\", fmt='%.6f')\n",
    "\n",
    "np.savetxt(\"2test_stacker_lgbm1.gz\", np.array(b['sum']), delimiter=\",\", fmt='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 12)\n",
      "(2345796, 12)\n",
      "(323432, 12)\n",
      "(80858, 12)\n",
      "Oversampling started for proportion: 0.369026565089\n",
      "Oversampling done, new proportion: 0.191259632688\n",
      "Oversampling started for proportion: 0.369883004774\n",
      "Oversampling done, new proportion: 0.191181170815\n",
      "(323432, 12)\n",
      "(80858, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "bst = KNeighborsClassifier(n_neighbors=1024, weights='uniform', algorithm='auto', leaf_size=30, \n",
    "                                p=2, metric='minkowski', metric_params=None, n_jobs=1, )\n",
    "\n",
    "x_train = np.column_stack((xgbtr,xgbtr1,lbmtr,nntr,nntr1,lstmtr1,sgtr,rftr,lrtr,glvtr,lstmtr2,sbtr1))\n",
    "\n",
    "x_test = np.column_stack((xgbts,xgbts1,lbmts,nnts,nnts1,lstmts1,sgts,rfts,lrts,glvts,lstmts2,sbts1))\n",
    "\n",
    "print x_train.shape\n",
    "print x_test.shape\n",
    "\n",
    "x_train[~np.isfinite(x_train)] = 0\n",
    "x_test[~np.isfinite(x_test)] = 0\n",
    "\n",
    "cv_scores = []\n",
    "oof_preds = []\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "# for dev_index, val_index in kf.split(range(x_train.shape[0])):\n",
    "for dev_index, val_index in kf.split(range(x_train.shape[0])):\n",
    "        dev_X, val_X = x_train[dev_index,:], x_train[val_index,:]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "        \n",
    "        pos_train = dev_X[dev_y == 1]\n",
    "        neg_train = dev_X[dev_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xd = np.concatenate((pos_train, neg_train))\n",
    "        yd = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        pos_train = val_X[val_y == 1]\n",
    "        neg_train = val_X[val_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xv = np.concatenate((pos_train, neg_train))\n",
    "        yv = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "\n",
    "#         t4 = lgbm.sklearn.LGBMClassifier(n_estimators=1000, seed=2016, **t4_params)\n",
    "#         bst = t4.fit(Xd, yd, \n",
    "#                        eval_set = [(Xv,yv)], eval_metric = 'logloss',early_stopping_rounds = 10, verbose =25) \n",
    "        bst.fit(Xd,yd)\n",
    "\n",
    "        preds = bst.predict_proba(Xv)\n",
    "        cv_scores.append(log_loss(yv, preds))\n",
    "\n",
    "        preds_tr = bst.predict_proba(x_test)\n",
    "\n",
    "        a = np.column_stack((a,preds_tr[:,1]))\n",
    "        print(cv_scores)\n",
    "\n",
    "        predsorg = bst.predict_proba(val_X)\n",
    "\n",
    "#         predictions = preds.reshape(-1,1)\n",
    "        no=0\n",
    "        for real_index in val_index:\n",
    "            for d in range (0,1):\n",
    "                train_stacker[real_index][d]=(predsorg[no][1])\n",
    "            no+=1\n",
    "    \n",
    "#     dev_X, val_X = x_train[dev_index,:], x_train[val_index,:]\n",
    "#         dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "#         model.fit(dev_X, dev_y)\n",
    "#         preds =  model.predict_proba(val_X)\n",
    "#         cv_scores.append(log_loss(val_y, preds))\n",
    "#         predictions = preds.reshape( val_X.shape[0], 3)\n",
    "#         print(cv_scores)\n",
    "#         no=0\n",
    "#         for real_index in val_index:\n",
    "#             for d in range (0,3):\n",
    "#                 train_stacker[real_index][d]=(predictions[no][d])\n",
    "#             no+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 118)\n",
      "(2345796, 118)\n"
     ]
    }
   ],
   "source": [
    "x_tr = np.column_stack((np.array(X),rstr[:,0:17],rstr[:,18:20],rspacetr[:,0:3],magic2tr,magic3tr,sbenchtr,\n",
    "                           np.array(mgtr.iloc[:,2]),pgtr,sbtr1))\n",
    "\n",
    "x_ts = np.column_stack((np.array(xtest),rsts[:,0:17],rsts[:,18:20],rspacets[:,0:3],magic2ts,magic3ts,sbenchts,\n",
    "                          np.array(mgts.iloc[:,2]),pgts,sbts1))\n",
    "\n",
    "print x_tr.shape\n",
    "print x_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"train_nlp_feat.gz\", x_tr, delimiter=\",\", fmt='%.6f')\n",
    "\n",
    "np.savetxt(\"test_nlp_feat.gz\", x_ts, delimiter=\",\", fmt='%.6f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
