{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               int64\n",
      "is_duplicate     int64\n",
      "qid1             int64\n",
      "qid2             int64\n",
      "question1       object\n",
      "question2       object\n",
      "test_id          int64\n",
      "dtype: object\n",
      "0    0.630802\n",
      "1    0.369198\n",
      "Name: is_duplicate, dtype: float64\n",
      "Maximum among duplicates:        196.0\n",
      "Maximum among non-duplicates:      1080.0\n",
      "Maximum among non-duplicates:  394\n",
      "Standard deviation in duplicates: 14.3821\n",
      "New value:               224.764198303\n",
      "Maximum among duplicates:        6.66666666667\n",
      "Maximum among non-duplicates:       117.0\n",
      "Number of lines greater than threshold:  152\n",
      "Number of lines greater than threshold:  0.376106045115\n",
      "New value:                7.4188787569\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import  division\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import itertools as it\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# import eli5\n",
    "from IPython.display import display\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "df_train = pd.read_csv('train.csv', \n",
    "                       dtype={\n",
    "                           'question1': np.str,\n",
    "                           'question2': np.str\n",
    "                       })\n",
    "df_train['test_id'] = -1\n",
    "df_test = pd.read_csv('test.csv', \n",
    "                      dtype={\n",
    "                          'question1': np.str,\n",
    "                          'question2': np.str\n",
    "                      })\n",
    "df_test['id'] = -1\n",
    "df_test['qid1'] = -1\n",
    "df_test['qid2'] = -1\n",
    "df_test['is_duplicate'] = -1\n",
    "\n",
    "df = pd.concat([df_train, df_test])\n",
    "df['question1'] = df['question1'].fillna('')\n",
    "df['question2'] = df['question2'].fillna('')\n",
    "df['uid'] = np.arange(df.shape[0])\n",
    "df = df.set_index(['uid'])\n",
    "print(df.dtypes)\n",
    "del(df_train, df_test)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "ix_train = np.where(df['id'] >= 0)[0]\n",
    "ix_test = np.where(df['id'] == -1)[0]\n",
    "ix_is_dup = np.where(df['is_duplicate'] == 1)[0]\n",
    "ix_not_dup = np.where(df['is_duplicate'] == 0)[0]\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "print(df[df['is_duplicate'] >= 0]['is_duplicate'].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "df['len1'] = df['question1'].str.len().astype(np.float32)\n",
    "df['len2'] = df['question2'].str.len().astype(np.float32)\n",
    "df['abs_diff_len1_len2'] = np.abs(df['len1'] - df['len2'])\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "max_in_dup = df.loc[ix_is_dup]['abs_diff_len1_len2'].max()\n",
    "print('Maximum among duplicates:       ', max_in_dup)\n",
    "max_in_not_dups = df.loc[ix_not_dup]['abs_diff_len1_len2'].max()\n",
    "print('Maximum among non-duplicates:     ', max_in_not_dups)\n",
    "print('Maximum among non-duplicates: ', (df.loc[ix_train]['abs_diff_len1_len2'] > max_in_dup).sum())\n",
    "std_in_dups = df.loc[ix_is_dup]['abs_diff_len1_len2'].std()\n",
    "print('Standard deviation in duplicates:', std_in_dups)\n",
    "replace_value = max_in_dup + 2*std_in_dups\n",
    "print('New value:              ', replace_value)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "df['abs_diff_len1_len2'] = df['abs_diff_len1_len2'].apply(lambda x: x if x < replace_value else replace_value)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "df['log_abs_diff_len1_len2'] = np.log(df['abs_diff_len1_len2'] + 1)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "df['ratio_len1_len2'] = df['len1'].apply(lambda x: x if x > 0.0 else 1.0)/                        df['len2'].apply(lambda x: x if x > 0.0 else 1.0)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "max_in_dup = df.loc[ix_is_dup]['ratio_len1_len2'].max()\n",
    "print('Maximum among duplicates:       ', max_in_dup)\n",
    "max_in_not_dups = df.loc[ix_not_dup]['ratio_len1_len2'].max()\n",
    "print('Maximum among non-duplicates:      ', max_in_not_dups)\n",
    "print('Number of lines greater than threshold: ', (df.loc[ix_train]['ratio_len1_len2'] > max_in_dup).sum())\n",
    "std_in_dups = df.loc[ix_is_dup]['ratio_len1_len2'].std()\n",
    "print('Number of lines greater than threshold: ', std_in_dups)\n",
    "replace_value = max_in_dup + 2*std_in_dups\n",
    "print('New value:               ', replace_value)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "df['ratio_len1_len2'] = df['ratio_len1_len2'].apply(lambda x: x if x < replace_value else replace_value)\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "df['log_ratio_len1_len2'] = np.log(df['ratio_len1_len2'] + 1)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 s, sys: 17.6 ms, total: 2.18 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "# if os.path.isfile('./../tmp/cv_char.pkl') and os.path.isfile('./../tmp/ch_freq.pkl'):\n",
    "with open('cv_char.pkl', 'rb') as f:\n",
    "    cv_char = pickle.load(f)\n",
    "with open('ch_freq.pkl', 'rb') as f:\n",
    "    ch_freq = pickle.load(f)\n",
    "# else:\n",
    "#     cv_char = CountVectorizer(ngram_range=(1, 3), analyzer='char')\n",
    "#     ch_freq = np.array(cv_char.fit_transform(df['question1'].tolist() + df['question2'].tolist()).sum(axis=0))[0, :]\n",
    "#     with open('cv_char.pkl', 'wb') as f:\n",
    "#         pickle.dump(cv_char, f)\n",
    "#     with open('ch_freq.pkl', 'wb') as f:\n",
    "#         pickle.dump(ch_freq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Unigrams:', 1779)\n",
      "('Bigrams: ', 10722)\n",
      "('Trigrams:', 74806)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "unigrams = dict([(k, v) for (k, v) in cv_char.vocabulary_.items() if len(k) == 1])\n",
    "ix_unigrams = np.sort(unigrams.values())\n",
    "print('Unigrams:', len(unigrams))\n",
    "bigrams = dict([(k, v) for (k, v) in cv_char.vocabulary_.items() if len(k) == 2])\n",
    "ix_bigrams = np.sort(bigrams.values())\n",
    "print('Bigrams: ', len(bigrams))\n",
    "trigrams = dict([(k, v) for (k, v) in cv_char.vocabulary_.items() if len(k) == 3])\n",
    "ix_trigrams = np.sort(trigrams.values())\n",
    "print('Trigrams:', len(trigrams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 14.3 s, total: 36.2 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "def save_sparse_csr(fname, sm):\n",
    "    np.savez(fname, \n",
    "             data=sm.data, \n",
    "             indices=sm.indices,\n",
    "             indptr=sm.indptr, \n",
    "             shape=sm.shape)\n",
    "\n",
    "def load_sparse_csr(fname):\n",
    "    loader = np.load(fname)\n",
    "    return sparse.csr_matrix((\n",
    "        loader['data'], \n",
    "        loader['indices'], \n",
    "        loader['indptr']),\n",
    "        shape=loader['shape'])\n",
    "\n",
    "# if os.path.isfile('m_q1.npz') and os.path.isfile('m_q2.npz'):\n",
    "m_q1 = load_sparse_csr('m_q1.npz')\n",
    "m_q2 = load_sparse_csr('m_q2.npz')\n",
    "# else:\n",
    "#     m_q1 = cv_char.transform(df['question1'].values)\n",
    "#     m_q2 = cv_char.transform(df['question2'].values)\n",
    "#     save_sparse_csr('m_q1.npz', m_q1)\n",
    "#     save_sparse_csr('m_q2.npz', m_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v_num = (m_q1[:, ix_unigrams] > 0).minimum((m_q2[:, ix_unigrams] > 0)).sum(axis=1)\n",
    "v_den = (m_q1[:, ix_unigrams] > 0).maximum((m_q2[:, ix_unigrams] > 0)).sum(axis=1)\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['unigram_jaccard'] = v_score\n",
    "# plot_real_feature('unigram_jaccard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# We take into account each letter more than once\n",
    "v_num = m_q1[:, ix_unigrams].minimum(m_q2[:, ix_unigrams]).sum(axis=1)\n",
    "v_den = m_q1[:, ix_unigrams].sum(axis=1) + m_q2[:, ix_unigrams].sum(axis=1)\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['unigram_all_jaccard'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We take into account each letter more than once\n",
    "# Normalize the maximum value, and not the sum\n",
    "v_num = m_q1[:, ix_unigrams].minimum(m_q2[:, ix_unigrams]).sum(axis=1)\n",
    "v_den = m_q1[:, ix_unigrams].maximum(m_q2[:, ix_unigrams]).sum(axis=1)\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['unigram_all_jaccard_max'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v_num = (m_q1[:, ix_bigrams] > 0).minimum((m_q2[:, ix_bigrams] > 0)).sum(axis=1)\n",
    "v_den = (m_q1[:, ix_bigrams] > 0).maximum((m_q2[:, ix_bigrams] > 0)).sum(axis=1)\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['bigram_jaccard'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We take into account each letter more than once\n",
    "v_num = m_q1[:, ix_bigrams].minimum(m_q2[:, ix_bigrams]).sum(axis=1)\n",
    "v_den = m_q1[:, ix_bigrams].sum(axis=1) + m_q2[:, ix_bigrams].sum(axis=1)\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['bigram_all_jaccard'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>test_id</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>abs_diff_len1_len2</th>\n",
       "      <th>log_abs_diff_len1_len2</th>\n",
       "      <th>ratio_len1_len2</th>\n",
       "      <th>log_ratio_len1_len2</th>\n",
       "      <th>unigram_jaccard</th>\n",
       "      <th>unigram_all_jaccard</th>\n",
       "      <th>unigram_all_jaccard_max</th>\n",
       "      <th>bigram_jaccard</th>\n",
       "      <th>bigram_all_jaccard</th>\n",
       "      <th>bigram_all_jaccard_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>-1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>0.769133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>-1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.457137</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.352518</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>0.442105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>-1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.237288</td>\n",
       "      <td>0.805264</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.397849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>-1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.570545</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.286957</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.061947</td>\n",
       "      <td>0.066038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>-1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>1.948718</td>\n",
       "      <td>1.081370</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.203540</td>\n",
       "      <td>0.255556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  is_duplicate  qid1  qid2  \\\n",
       "uid                                 \n",
       "0     0             0     1     2   \n",
       "1     1             0     3     4   \n",
       "2     2             0     5     6   \n",
       "3     3             0     7     8   \n",
       "4     4             0     9    10   \n",
       "\n",
       "                                             question1  \\\n",
       "uid                                                      \n",
       "0    What is the step by step guide to invest in sh...   \n",
       "1    What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2    How can I increase the speed of my internet co...   \n",
       "3    Why am I mentally very lonely? How can I solve...   \n",
       "4    Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                             question2  test_id  len1  len2  \\\n",
       "uid                                                                           \n",
       "0    What is the step by step guide to invest in sh...       -1  66.0  57.0   \n",
       "1    What would happen if the Indian government sto...       -1  51.0  88.0   \n",
       "2    How can Internet speed be increased by hacking...       -1  73.0  59.0   \n",
       "3    Find the remainder when [math]23^{24}[/math] i...       -1  50.0  65.0   \n",
       "4              Which fish would survive in salt water?       -1  76.0  39.0   \n",
       "\n",
       "     abs_diff_len1_len2  log_abs_diff_len1_len2  ratio_len1_len2  \\\n",
       "uid                                                                \n",
       "0                   9.0                2.302585         1.157895   \n",
       "1                  37.0                3.637586         0.579545   \n",
       "2                  14.0                2.708050         1.237288   \n",
       "3                  15.0                2.772589         0.769231   \n",
       "4                  37.0                3.637586         1.948718   \n",
       "\n",
       "     log_ratio_len1_len2  unigram_jaccard  unigram_all_jaccard  \\\n",
       "uid                                                              \n",
       "0               0.769133         1.000000             0.463415   \n",
       "1               0.457137         0.703704             0.352518   \n",
       "2               0.805264         0.750000             0.386364   \n",
       "3               0.570545         0.466667             0.286957   \n",
       "4               1.081370         0.653846             0.313043   \n",
       "\n",
       "     unigram_all_jaccard_max  bigram_jaccard  bigram_all_jaccard  \\\n",
       "uid                                                                \n",
       "0                   0.863636        0.886364            0.454545   \n",
       "1                   0.544444        0.500000            0.306569   \n",
       "2                   0.629630        0.425000            0.284615   \n",
       "3                   0.402439        0.081395            0.061947   \n",
       "4                   0.455696        0.289474            0.203540   \n",
       "\n",
       "     bigram_all_jaccard_max  \n",
       "uid                          \n",
       "0                  0.833333  \n",
       "1                  0.442105  \n",
       "2                  0.397849  \n",
       "3                  0.066038  \n",
       "4                  0.255556  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v_num = m_q1[:, ix_bigrams].minimum(m_q2[:, ix_bigrams]).sum(axis=1)\n",
    "v_den = m_q1[:, ix_bigrams].maximum(m_q2[:, ix_bigrams]).sum(axis=1)\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['bigram_all_jaccard_max'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m_q1 = m_q1[:, ix_trigrams]\n",
    "m_q2 = m_q2[:, ix_trigrams]\n",
    "# In [45]:\n",
    "v_num = (m_q1 > 0).minimum((m_q2 > 0)).sum(axis=1)\n",
    "v_den = (m_q1 > 0).maximum((m_q2 > 0)).sum(axis=1)\n",
    "v_den[np.where(v_den == 0)] = 1\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['trigram_jaccard'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v_num = m_q1.minimum(m_q2).sum(axis=1)\n",
    "v_den = m_q1.sum(axis=1) + m_q2.sum(axis=1)\n",
    "v_den[np.where(v_den == 0)] = 1\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['trigram_all_jaccard'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v_num = m_q1.minimum(m_q2).sum(axis=1)\n",
    "v_den = m_q1.maximum(m_q2).sum(axis=1)\n",
    "v_den[np.where(v_den == 0)] = 1\n",
    "v_score = np.array(v_num.flatten()).astype(np.float32)[0, :]/np.array(v_den.flatten())[0, :]\n",
    "\n",
    "df['trigram_all_jaccard_max'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tft = TfidfTransformer(\n",
    "    norm='l2', \n",
    "    use_idf=True, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False)\n",
    "\n",
    "tft = tft.fit(sparse.vstack((m_q1, m_q2)))\n",
    "m_q1_tf = tft.transform(m_q1)\n",
    "m_q2_tf = tft.transform(m_q2)\n",
    "\n",
    "v_num = np.array(m_q1_tf.multiply(m_q2_tf).sum(axis=1))[:, 0]\n",
    "v_den = np.array(np.sqrt(m_q1_tf.multiply(m_q1_tf).sum(axis=1)))[:, 0] * \\\n",
    "        np.array(np.sqrt(m_q2_tf.multiply(m_q2_tf).sum(axis=1)))[:, 0]\n",
    "v_num[np.where(v_den == 0)] = 1\n",
    "v_den[np.where(v_den == 0)] = 1\n",
    "\n",
    "v_score = 1 - v_num/v_den\n",
    "\n",
    "df['trigram_tfidf_cosine'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tft = TfidfTransformer(\n",
    "    norm='l2', \n",
    "    use_idf=True, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False)\n",
    "\n",
    "tft = tft.fit(sparse.vstack((m_q1, m_q2)))\n",
    "m_q1_tf = tft.transform(m_q1)\n",
    "m_q2_tf = tft.transform(m_q2)\n",
    "\n",
    "v_score = (m_q1_tf - m_q2_tf)\n",
    "v_score = np.sqrt(np.array(v_score.multiply(v_score).sum(axis=1))[:, 0])\n",
    "\n",
    "df['trigram_tfidf_l2_euclidean'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tft = TfidfTransformer(\n",
    "    norm='l1', \n",
    "    use_idf=True, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False)\n",
    "\n",
    "tft = tft.fit(sparse.vstack((m_q1, m_q2)))\n",
    "m_q1_tf = tft.transform(m_q1)\n",
    "m_q2_tf = tft.transform(m_q2)\n",
    "\n",
    "v_score = (m_q1_tf - m_q2_tf)\n",
    "v_score = np.sqrt(np.array(v_score.multiply(v_score).sum(axis=1))[:, 0])\n",
    "\n",
    "df['trigram_tfidf_l1_euclidean'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tft = TfidfTransformer(\n",
    "    norm='l2', \n",
    "    use_idf=False, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False)\n",
    "\n",
    "tft = tft.fit(sparse.vstack((m_q1, m_q2)))\n",
    "m_q1_tf = tft.transform(m_q1)\n",
    "m_q2_tf = tft.transform(m_q2)\n",
    "\n",
    "v_score = (m_q1_tf - m_q2_tf)\n",
    "v_score = np.sqrt(np.array(v_score.multiply(v_score).sum(axis=1))[:, 0])\n",
    "\n",
    "df['trigram_tf_l2_euclidean'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'en_core_web_sm'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# df.head()['question1'].apply(lambda s: ' '.join([c.lemma_ for c in nlp(unicode(s)) if c.lemma_  != '?']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SYMBOLS = set(' '.join(string.punctuation).split(' ') + ['...', '“', '”', '\\'ve'])\n",
    "\n",
    "if not os.path.isfile('./../tmp/bow_lemma.pkl'):\n",
    "    q1 = []\n",
    "\n",
    "    for doc in nlp.pipe(df['question1'].str.decode('utf-8'), n_threads=16, batch_size=10000):\n",
    "        q1.append([c.lemma_ for c in doc if c.lemma_ not in SYMBOLS])\n",
    "\n",
    "    q2 = []\n",
    "\n",
    "    for doc in nlp.pipe(df['question2'].str.decode('utf-8'), n_threads=16, batch_size=10000):\n",
    "        q2.append([c.lemma_ for c in doc if c.lemma_ not in SYMBOLS])\n",
    "        \n",
    "    with open('bow_lemma.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'q1': q1,\n",
    "            'q2': q2\n",
    "        }, f)\n",
    "else:\n",
    "    with open('./../tmp/bow_lemma.pkl', 'rb') as f:\n",
    "        tmp = pickle.load(f)\n",
    "        q1 = tmp['q1']\n",
    "        q2 = tmp['q2']\n",
    "        del(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.4 s, sys: 361 ms, total: 31.7 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.isfile('./../tmp/cv_word_lemma.pkl') and os.path.isfile('./../tmp/wl_freq.pkl'):\n",
    "    with open('./../tmp/cv_word_lemma.pkl', 'rb') as f:\n",
    "        cv_words = pickle.load(f)\n",
    "    with open('./../tmp/wl_freq.pkl', 'rb') as f:\n",
    "        w_freq = pickle.load(f)\n",
    "else:\n",
    "    cv_words = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n",
    "    w_freq = np.array(cv_words.fit_transform(\n",
    "        [' '.join(s) for s in q1] + [' '.join(s) for s in q2]).sum(axis=0))[0, :]\n",
    "    with open('cv_word_lemma.pkl', 'wb') as f:\n",
    "        pickle.dump(cv_words, f)\n",
    "    with open('wl_freq.pkl', 'wb') as f:\n",
    "        pickle.dump(w_freq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('./../tmp/m_q1_wl.npz') and os.path.isfile('./../tmp/m_q2_wl.npz'):\n",
    "    m_q1 = load_sparse_csr('./../tmp/m_q1_wl.npz')\n",
    "    m_q2 = load_sparse_csr('./../tmp/m_q2_wl.npz')\n",
    "else:\n",
    "    m_q1 = cv_words.transform([' '.join(s) for s in q1])\n",
    "    m_q2 = cv_words.transform([' '.join(s) for s in q2])\n",
    "    save_sparse_csr('m_q1_wl.npz', m_q1)\n",
    "    save_sparse_csr('m_q2_wl.npz', m_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tft = TfidfTransformer(\n",
    "    norm='l2', \n",
    "    use_idf=True, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False)\n",
    "\n",
    "tft = tft.fit(sparse.vstack((m_q1, m_q2)))\n",
    "m_q1_tf = tft.transform(m_q1)\n",
    "m_q2_tf = tft.transform(m_q2)\n",
    "\n",
    "v_num = np.array(m_q1_tf.multiply(m_q2_tf).sum(axis=1))[:, 0]\n",
    "v_den = np.array(np.sqrt(m_q1_tf.multiply(m_q1_tf).sum(axis=1)))[:, 0] * \\\n",
    "        np.array(np.sqrt(m_q2_tf.multiply(m_q2_tf).sum(axis=1)))[:, 0]\n",
    "v_num[np.where(v_den == 0)] = 1\n",
    "v_den[np.where(v_den == 0)] = 1\n",
    "\n",
    "v_score = 1 - v_num/v_den\n",
    "\n",
    "df['1wl_tfidf_cosine'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tft = TfidfTransformer(\n",
    "    norm='l2', \n",
    "    use_idf=True, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False)\n",
    "\n",
    "tft = tft.fit(sparse.vstack((m_q1, m_q2)))\n",
    "m_q1_tf = tft.transform(m_q1)\n",
    "m_q2_tf = tft.transform(m_q2)\n",
    "\n",
    "v_score = (m_q1_tf - m_q2_tf)\n",
    "v_score = np.sqrt(np.array(v_score.multiply(v_score).sum(axis=1))[:, 0])\n",
    "\n",
    "df['1wl_tfidf_l2_euclidean'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tft = TfidfTransformer(\n",
    "    norm='l2', \n",
    "    use_idf=False, \n",
    "    smooth_idf=True, \n",
    "    sublinear_tf=False)\n",
    "\n",
    "tft = tft.fit(sparse.vstack((m_q1, m_q2)))\n",
    "m_q1_tf = tft.transform(m_q1)\n",
    "m_q2_tf = tft.transform(m_q2)\n",
    "\n",
    "v_score = (m_q1_tf - m_q2_tf)\n",
    "v_score = np.sqrt(np.array(v_score.multiply(v_score).sum(axis=1))[:, 0])\n",
    "\n",
    "df['1wl_tf_l2_euclidean'] = v_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test = df[df.is_duplicate < 0 ]\n",
    "\n",
    "# df_train = df[df.test_id == -1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>test_id</th>\n",
       "      <th>len1</th>\n",
       "      <th>len2</th>\n",
       "      <th>abs_diff_len1_len2</th>\n",
       "      <th>log_abs_diff_len1_len2</th>\n",
       "      <th>ratio_len1_len2</th>\n",
       "      <th>log_ratio_len1_len2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404290</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.608806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404291</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>1.534884</td>\n",
       "      <td>0.930148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404292</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>2.068966</td>\n",
       "      <td>1.121341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404293</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.588235</td>\n",
       "      <td>0.950976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404294</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "      <td>4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.725937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  is_duplicate  qid1  qid2  \\\n",
       "uid                                    \n",
       "404290  -1            -1    -1    -1   \n",
       "404291  -1            -1    -1    -1   \n",
       "404292  -1            -1    -1    -1   \n",
       "404293  -1            -1    -1    -1   \n",
       "404294  -1            -1    -1    -1   \n",
       "\n",
       "                                                question1  \\\n",
       "uid                                                         \n",
       "404290  How does the Surface Pro himself 4 compare wit...   \n",
       "404291  Should I have a hair transplant at age 24? How...   \n",
       "404292  What but is the best way to send money from Ch...   \n",
       "404293                        Which food not emulsifiers?   \n",
       "404294                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                                question2  test_id  len1  \\\n",
       "uid                                                                        \n",
       "404290  Why did Microsoft choose core m3 and not core ...        0  57.0   \n",
       "404291        How much cost does hair transplant require?        1  66.0   \n",
       "404292                      What you send money to China?        2  60.0   \n",
       "404293                                  What foods fibre?        3  27.0   \n",
       "404294                     How their can I start reading?        4  32.0   \n",
       "\n",
       "        len2  abs_diff_len1_len2  log_abs_diff_len1_len2  ratio_len1_len2  \\\n",
       "uid                                                                         \n",
       "404290  68.0                11.0                2.484907         0.838235   \n",
       "404291  43.0                23.0                3.178054         1.534884   \n",
       "404292  29.0                31.0                3.465736         2.068966   \n",
       "404293  17.0                10.0                2.397895         1.588235   \n",
       "404294  30.0                 2.0                1.098612         1.066667   \n",
       "\n",
       "        log_ratio_len1_len2  \n",
       "uid                          \n",
       "404290             0.608806  \n",
       "404291             0.930148  \n",
       "404292             1.121341  \n",
       "404293             0.950976  \n",
       "404294             0.725937  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test.iloc[:,9:].to_csv('russ_test.csv', index = False)\n",
    "\n",
    "df_train.iloc[:,9:].to_csv('russ_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = np.array(df_test.iloc[:,9:])\n",
    "\n",
    "np.savetxt('russ_alt.csv', test, delimiter=\",\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
