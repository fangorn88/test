{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:22: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:34: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:36: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:65: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 213)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import  division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "x1 = pd.read_csv('train_features.csv')\n",
    "x2 = pd.read_csv('magicfeat_train.csv')\n",
    "x3 = pd.read_csv('fanokas.csv')\n",
    "x4 = pd.read_csv('owl_feat.csv')\n",
    "x5 = pd.read_csv('jacfeat.csv')\n",
    "\n",
    "col_to_drop = ['z_len1','z_len2','z_word_len1','z_word_len2','z_word_match']\n",
    "\n",
    "x4.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "xf = pd.concat([x1,x2.ix[:,2:],x3.ix[:,1:],x4.ix[:,9:],x5.ix[:,1:]], axis = 1)\n",
    "\n",
    "x1t = pd.read_csv('test_features.csv')\n",
    "x2t = pd.read_csv('magicfeat_test.csv')\n",
    "x3t = pd.read_csv('fanokas_test.csv')\n",
    "x4t = pd.read_csv('owl_feat_test.csv')\n",
    "x5t = pd.read_csv('jacfeat_test.csv')\n",
    "\n",
    "col_to_drop = ['z_len1','z_len2','z_word_len1','z_word_len2','z_word_match']\n",
    "\n",
    "x4t.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "xft = pd.concat([x1t,x2t.ix[:,2:],x3t.ix[:,1:],x4t.ix[:,6:],x5t.ix[:,1:]], axis = 1)\n",
    "\n",
    "X = xf.ix[:,2:]\n",
    "\n",
    "y = X['is_duplicate'].values\n",
    "\n",
    "X.drop('is_duplicate', inplace = True, axis = 1)\n",
    "\n",
    "col_to_drop = ['q1_hash','q2_hash']\n",
    "\n",
    "X.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "sbtr = np.loadtxt(\"sbenchfeat_tsvd100_train.gz\", delimiter=\",\")\n",
    "rstr = np.loadtxt(\"russ_tr.gz\", delimiter=\",\")\n",
    "rspacetr = np.loadtxt(\"russpacy_tr.gz\", delimiter=\",\")\n",
    "\n",
    "sbts = np.loadtxt(\"sbenchfeat_tsvd100_test.gz\", delimiter=\",\")\n",
    "rsts = np.loadtxt(\"russ_ts.gz\", delimiter=\",\")\n",
    "rspacets = np.loadtxt(\"russpacy_ts.gz\", delimiter=\",\")\n",
    "\n",
    "\n",
    "magic2tr = np.loadtxt(\"magic2_tr.gz\", delimiter=\",\")\n",
    "magic2ts = np.loadtxt(\"magic2_ts.gz\", delimiter=\",\")\n",
    "\n",
    "magic3tr = np.loadtxt(\"magic3_tr.gz\", delimiter=\",\")\n",
    "magic3ts = np.loadtxt(\"magic3_ts.gz\", delimiter=\",\")\n",
    "\n",
    "x_train = np.column_stack((np.array(X),rstr[:,0:17],rstr[:,18:20],rspacetr[:,0:3],sbtr,magic2tr,magic3tr))\n",
    "\n",
    "print x_train.shape\n",
    "\n",
    "xtest = xft.ix[:,2:]\n",
    "\n",
    "col_to_drop = ['q1_hash','q2_hash']\n",
    "xtest.drop(col_to_drop, inplace = True, axis = 1)\n",
    "\n",
    "x_test = np.column_stack((np.array(xtest),rsts[:,0:17],rsts[:,18:20],rspacets[:,0:3],sbts,magic2ts,magic3ts))\n",
    "\n",
    "print x_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# xgbtr = np.loadtxt(\"train_stacker_xgb1.csv\", delimiter=\",\")\n",
    "# xgbts = np.loadtxt(\"test_stacker_xgb1.csv\", delimiter=\",\")\n",
    "\n",
    "# lstmtr = np.loadtxt(\"train_stacker_lstm2.csv\", delimiter=\",\")\n",
    "# lstmts = np.loadtxt(\"test_stacker_lstm2.csv\", delimiter=\",\")\n",
    "\n",
    "lstmtr1 = np.loadtxt(\"train_stacker_lstm4.csv\", delimiter=\",\")\n",
    "lstmts1 = np.loadtxt(\"test_stacker_lstm4.csv\", delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mgtr = pd.read_csv('new_magic_train.csv')\n",
    "# mgts = pd.read_csv('new_magic_test.csv')                \n",
    "\n",
    "pgtr = pd.read_csv('pagerank_train.csv')\n",
    "pgts = pd.read_csv('pagerank_test.csv')                \n",
    "\n",
    "# mgts.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# id_tr = np.array(range(0,x_train.shape[0]))\n",
    "# id_ts = np.array(range(0,x_test.shape[0]))\n",
    "\n",
    "xgb_metatr = np.loadtxt(\"2train_stacker_xgb1.csv\", delimiter=\",\")\n",
    "xgb_metats = np.loadtxt(\"2test_stacker_xgb1.csv\", delimiter=\",\")\n",
    "\n",
    "nn_metatr = np.array(pd.read_csv('2train_stacker_nn1.csv'))\n",
    "nn_metats = np.loadtxt(\"2test_stacker_nn1.gz\", delimiter=\",\")\n",
    "\n",
    "# id_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 126)\n",
      "(2345796, 126)\n"
     ]
    }
   ],
   "source": [
    "# nntr = np.array(pd.read_csv('train_stacker.csv'))\n",
    "# nnts = np.loadtxt(\"test_stacker_nn1.csv\", delimiter=\",\")\n",
    "\n",
    "# rftr = np.loadtxt(\"train_stacker_rf1.csv\", delimiter=\",\")\n",
    "# rfts = np.loadtxt(\"test_stacker_rf1.csv\", delimiter=\",\")\n",
    "\n",
    "# lrtr = np.loadtxt(\"train_stacker_lr1.csv\", delimiter=\",\")\n",
    "# lrts = np.loadtxt(\"test_stacker_lr1.csv\", delimiter=\",\")\n",
    "\n",
    "# nntr1 = np.array(pd.read_csv('train_stacker_nn2.csv'))\n",
    "# nnts1 = np.loadtxt(\"test_stacker_nn2.csv\", delimiter=\",\")\n",
    "\n",
    "# glvtr = np.loadtxt(\"train_stacker_glv1.csv\", delimiter=\",\")\n",
    "# glvts = np.loadtxt(\"test_stacker_glv1.csv\", delimiter=\",\")\n",
    "\n",
    "# lstmtr2 = np.loadtxt(\"train_stacker_lstm4t.csv\", delimiter=\",\")\n",
    "# lstmts2 = np.loadtxt(\"test_stacker_lstm4t.csv\", delimiter=\",\")\n",
    "\n",
    "# sgtr = np.loadtxt(\"train_stacker_sgd1.csv\", delimiter=\",\")\n",
    "# sgts = np.loadtxt(\"test_stacker_sgd1.csv\", delimiter=\",\")\n",
    "\n",
    "# sbenchtr = np.loadtxt(\"train_stacker_sbench1.csv\", delimiter=\",\")\n",
    "# sbenchts = np.loadtxt(\"test_stacker_sbench1.csv\", delimiter=\",\")\n",
    "\n",
    "# x_train = np.column_stack((np.array(X),rstr[:,0:17],rstr[:,18:20],rspacetr[:,0:3],sbtr,magic2tr,magic3tr,sbenchtr,\n",
    "#                            np.array(mgtr.iloc[:,2]),xgbtr,nntr,rftr,lstmtr1,lrtr,nntr1,sgtr,glvtr,lstmtr2,pgtr))\n",
    "\n",
    "# x_test = np.column_stack((np.array(xtest),rsts[:,0:17],rsts[:,18:20],rspacets[:,0:3],sbts,magic2ts,magic3ts,sbenchts,\n",
    "#                           np.array(mgts.iloc[:,2]),xgbts,nnts,rfts,lstmts1,lrts,nnts1,sgts,glvts,lstmts2,pgts))\n",
    "\n",
    "x_train = np.column_stack((np.array(X),rstr[:,0:17],rstr[:,18:20],rspacetr[:,0:3],magic2tr,magic3tr,sbenchtr,\n",
    "                           np.array(mgtr.iloc[:,2]),xgbtr,nntr,rftr,lstmtr1,lrtr,nntr1,sgtr,glvtr,lstmtr2,pgtr))\n",
    "\n",
    "x_test = np.column_stack((np.array(xtest),rsts[:,0:17],rsts[:,18:20],rspacets[:,0:3],magic2ts,magic3ts,sbenchts,\n",
    "                          np.array(mgts.iloc[:,2]),xgbts,nnts,rfts,lstmts1,lrts,nnts1,sgts,glvts,lstmts2,pgts))\n",
    "\n",
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import  division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "x_train = np.loadtxt(\"lstm_feat_train.gz\",  delimiter=\",\" )\n",
    "\n",
    "x_test = np.loadtxt(\"lstm_feat_test.gz\",  delimiter=\",\")\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "y = df['is_duplicate'].values\n",
    "\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "(323432, 160)\n",
      "(80858, 160)\n",
      "Oversampling started for proportion: 0.369026565089\n",
      "Oversampling done, new proportion: 0.191259632688\n",
      "Oversampling started for proportion: 0.369883004774\n",
      "Oversampling done, new proportion: 0.191181170815\n",
      "(323432, 160)\n",
      "(80858, 160)\n",
      "[0]\ttrain-logloss:0.639324\tvalid-logloss:0.640547\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 10 rounds.\n",
      "[100]\ttrain-logloss:0.245993\tvalid-logloss:0.299049\n",
      "[200]\ttrain-logloss:0.202788\tvalid-logloss:0.287789\n",
      "[300]\ttrain-logloss:0.172627\tvalid-logloss:0.284174\n",
      "[400]\ttrain-logloss:0.148141\tvalid-logloss:0.282604\n",
      "Stopping. Best iteration:\n",
      "[401]\ttrain-logloss:0.147989\tvalid-logloss:0.282601\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/metrics/classification.py:1662: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/metrics/classification.py:1662: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n",
      "(323432, 160)\n",
      "(80858, 160)\n",
      "Oversampling started for proportion: 0.368834871008\n",
      "Oversampling done, new proportion: 0.191277675158\n",
      "Oversampling started for proportion: 0.370649781098\n",
      "Oversampling done, new proportion: 0.191112046372\n",
      "(323432, 160)\n",
      "(80858, 160)\n",
      "[0]\ttrain-logloss:0.63925\tvalid-logloss:0.640535\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 10 rounds.\n",
      "[100]\ttrain-logloss:0.247148\tvalid-logloss:0.299636\n",
      "[200]\ttrain-logloss:0.202038\tvalid-logloss:0.288244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bb3b7713fc7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;31m# ntree_limit=model.best_ntree_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RS = 2016\n",
    "ROUNDS = 400\n",
    "\n",
    "print(\"Started\")\n",
    "np.random.seed(RS)\n",
    "input_folder = ''\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.11\n",
    "params['max_depth'] = 9\n",
    "params['seed'] = RS\n",
    "params['gamma'] = 0.5\n",
    "params['subsample'] = 0.75\n",
    "params['colsample_bytree'] = 0.75\n",
    "params['min_child_weight'] = 10\n",
    "params['reg_alpha'] = 2\n",
    "params['n_jobs'] = 12\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "y_train = np.array(y)\n",
    "\n",
    "train_stacker=[ [0.0 for s in range(1)]  for k in range (0,(x_train.shape[0])) ]\n",
    "\n",
    "cv_scores = []\n",
    "oof_preds = []\n",
    "a = [0 for x in range(2345796)]\n",
    "# StratifiedKFold\n",
    "# kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=RS)\n",
    "# for dev_index, val_index in kf.split(range(x_train.shape[0]),y_train):\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(x_train.shape[0])):\n",
    "        dev_X, val_X = x_train[dev_index,:], x_train[val_index,:]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "        \n",
    "        pos_train = dev_X[dev_y == 1]\n",
    "        neg_train = dev_X[dev_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xd = np.concatenate((pos_train, neg_train))\n",
    "        yd = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        pos_train = val_X[val_y == 1]\n",
    "        neg_train = val_X[val_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xv = np.concatenate((pos_train, neg_train))\n",
    "        yv = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "\n",
    "        d_train = xgb.DMatrix(Xd, label=yd)\n",
    "        d_valid = xgb.DMatrix(Xv, label=yv)\n",
    "\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        bst = xgb.train(params, d_train, 1000, watchlist, early_stopping_rounds=10, verbose_eval=100)\n",
    "        # ntree_limit=model.best_ntree_limit\n",
    "        preds = bst.predict(d_valid, ntree_limit=bst.best_ntree_limit)\n",
    "        cv_scores.append(log_loss(yv, preds))\n",
    "        print(cv_scores)\n",
    "#         break\n",
    "        \n",
    "        d_test = xgb.DMatrix(x_test)\n",
    "        preds_tr = bst.predict(d_test, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "        a = np.column_stack((a,preds_tr))\n",
    "\n",
    "        d_valorg = xgb.DMatrix(val_X, label=val_y)\n",
    "        predsorg = bst.predict(d_valorg, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "#         predictions = preds.reshape(-1,1)\n",
    "        no=0\n",
    "        for real_index in val_index:\n",
    "            for d in range (0,1):\n",
    "                train_stacker[real_index][d]=(predsorg[no])\n",
    "            no+=1\n",
    "\n",
    "# [0.15360504630455896, 0.15447078993338806, 0.15552687734108414, 0.15476172066330016, 0.15241640738176887]\n",
    "# [0.15311663729837133, 0.15390724875863718, 0.15488412233071547, 0.15409576186936139, 0.15184966391506896]\n",
    "# [0.15263729582890673, 0.15299274474295882, 0.15413732150213838, 0.15329555282049126, 0.15168823883360641]\n",
    "# [0.15211336771315526, 0.15263665115074093, 0.15316278739909817, 0.15283526907831582, 0.15115565771008421]\n",
    "# [0.14679638005158449, 0.14643568394088646, 0.14695301106657524, 0.14738008193419261, 0.14605956315322077]\n",
    "# [0.14629926832710563, 0.14606952289254052, 0.14638265721616533, 0.14687541244637101, 0.14573516873536307]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "b = pd.DataFrame(a)\n",
    "\n",
    "b['sum'] = b.sum(axis = 1)/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = x4t['test_id']\n",
    "sub['is_duplicate'] = b['sum']\n",
    "sub.to_csv(\"xgb2016_xgbnnlstm_14.csv\", index=False)\n",
    "# [0.17016885873458976][0.17057354196031635]\n",
    "# [0.14779218706406064, 0.14736209573863371, 0.14791776295751807, 0.14854973453415368, 0.14707683432508603]\n",
    "# [0.16395319948454035, 0.16342681680227539, 0.1645509607385589, 0.16476062285669904, 0.16366588193787229]\n",
    "# [0.16391499039074689, 0.16310379978781103, 0.1643765694535835, 0.16461148761217967, 0.16346322504582803]\n",
    "# [0.15594182184782154, 0.15636525572885629]\n",
    "# [0.15601431264055107, 0.15649749323218259, 0.15664772713794661, 0.15711803971832813, 0.15506936911164648] - md9\n",
    "# [0.15566405419387641, 0.15630713900809348, 0.15670020109376631, 0.15657009005989708, 0.15495084710684223] - md9n\n",
    "# [0.15554099102519406, 0.15602266978895404, 0.15628836502397056, 0.15601721137359009, 0.15455359581827885] - md7\n",
    "# [0.15558689011874977, 0.15590592436387529, 0.1564077030690208, 0.15590118071950423, 0.15445916419880135] - md6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"2train_stacker_xgb2.gz\", train_stacker, delimiter=\",\", fmt='%.6f')\n",
    "\n",
    "np.savetxt(\"2test_stacker_xgb2.gz\", np.array(b['sum']), delimiter=\",\", fmt='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "# 'metric': 'binary_logloss', 'num_boost_round' :1000,\n",
    "t4_params = {\n",
    "    'boosting_type': 'gbdt', 'objective': 'binary', 'nthread': 12, 'silent': True,\n",
    "    'num_leaves': 2**6, 'learning_rate': 0.05, 'max_depth': 6,\n",
    "    'max_bin': 255, 'subsample_for_bin': 50000,\n",
    "    'subsample': 0.85, 'subsample_freq': 1, 'colsample_bytree': 0.80, 'reg_alpha':2, 'reg_lambda':0,\n",
    "    'min_split_gain': 0.5, 'min_child_weight': 10, 'min_child_samples': 2, 'scale_pos_weight': 1}\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323432, 223)\n",
      "(80858, 223)\n",
      "Oversampling started for proportion: 0.369026565089\n",
      "Oversampling done, new proportion: 0.191259632688\n",
      "Oversampling started for proportion: 0.369883004774\n",
      "Oversampling done, new proportion: 0.191181170815\n",
      "(323432, 223)\n",
      "(80858, 223)\n",
      "Train until valid scores didn't improve in 10 rounds.\n",
      "[25]\tvalid_0's binary_logloss: 0.260576\n",
      "[50]\tvalid_0's binary_logloss: 0.178799\n",
      "[75]\tvalid_0's binary_logloss: 0.159463\n",
      "[100]\tvalid_0's binary_logloss: 0.154614\n",
      "[125]\tvalid_0's binary_logloss: 0.15329\n",
      "[150]\tvalid_0's binary_logloss: 0.152749\n",
      "[175]\tvalid_0's binary_logloss: 0.152486\n",
      "[200]\tvalid_0's binary_logloss: 0.152325\n",
      "[225]\tvalid_0's binary_logloss: 0.152232\n",
      "[250]\tvalid_0's binary_logloss: 0.152204\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's binary_logloss: 0.152197\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-1a6cf299b79c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m                        eval_set = [(Xv,yv)], eval_metric = 'logloss',early_stopping_rounds = 10, verbose =25) \n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/lightgbm-0.2-py2.7.egg/lightgbm/sklearn.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mpredicted_probability\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \"\"\"\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mclass_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/lightgbm-0.2-py2.7.egg/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m   1596\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_has_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/lightgbm-0.2-py2.7.egg/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             preds, nrow = self.__pred_for_np2d(data, num_iteration,\n\u001b[0;32m--> 409\u001b[0;31m                                                predict_type)\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             preds, nrow = self.__pred_for_np2d(data.values, num_iteration,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/lightgbm-0.2-py2.7.egg/lightgbm/basic.pyc\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_train = np.array(y)\n",
    "\n",
    "train_stacker=[ [0.0 for s in range(1)]  for k in range (0,(x_train.shape[0])) ]\n",
    "\n",
    "cv_scores = []\n",
    "oof_preds = []\n",
    "a = [0 for x in range(2345796)]\n",
    "# StratifiedKFold\n",
    "# kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=RS)\n",
    "# for dev_index, val_index in kf.split(range(x_train.shape[0]),y_train):\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(x_train.shape[0])):\n",
    "        dev_X, val_X = x_train[dev_index,:], x_train[val_index,:]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "        \n",
    "        pos_train = dev_X[dev_y == 1]\n",
    "        neg_train = dev_X[dev_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xd = np.concatenate((pos_train, neg_train))\n",
    "        yd = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        pos_train = val_X[val_y == 1]\n",
    "        neg_train = val_X[val_y == 0]\n",
    "\n",
    "        print(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "        p = 0.165\n",
    "        scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "        while scale > 1:\n",
    "            neg_train = np.concatenate((neg_train, neg_train))\n",
    "            scale -=1\n",
    "        neg_train = np.concatenate((neg_train, neg_train[:int(scale * len(neg_train))]))\n",
    "        print(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "        Xv = np.concatenate((pos_train, neg_train))\n",
    "        yv = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "        del pos_train, neg_train  \n",
    "\n",
    "        print dev_X.shape\n",
    "        print val_X.shape\n",
    "\n",
    "        t4 = lgbm.sklearn.LGBMClassifier(n_estimators=1000, seed=2016, **t4_params)\n",
    "        bst = t4.fit(Xd, yd, \n",
    "                       eval_set = [(Xv,yv)], eval_metric = 'logloss',early_stopping_rounds = 10, verbose =25) \n",
    "\n",
    "        preds = bst.predict_proba(Xv)\n",
    "        cv_scores.append(log_loss(yv, preds))\n",
    "\n",
    "        preds_tr = bst.predict_proba(x_test)\n",
    "\n",
    "        a = np.column_stack((a,preds_tr[:,1]))\n",
    "        print(cv_scores)\n",
    "\n",
    "        predsorg = bst.predict_proba(val_X)\n",
    "\n",
    "#         predictions = preds.reshape(-1,1)\n",
    "        no=0\n",
    "        for real_index in val_index:\n",
    "            for d in range (0,1):\n",
    "                train_stacker[real_index][d]=(predsorg[no][1])\n",
    "            no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# [0.15226098539926985, 0.15272025134286146, 0.1537800597815259, 0.15286225322434724, 0.151333317489694]\n",
    "b = pd.DataFrame(a)\n",
    "b['sum'] = b.sum(axis = 1)/5\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = x4t['test_id']\n",
    "sub['is_duplicate'] = b['sum']\n",
    "sub.to_csv(\"lgbm_xgbnnlstm_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231833</td>\n",
       "      <td>0.201949</td>\n",
       "      <td>0.193909</td>\n",
       "      <td>0.186294</td>\n",
       "      <td>0.187436</td>\n",
       "      <td>0.200284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109984</td>\n",
       "      <td>0.107898</td>\n",
       "      <td>0.103193</td>\n",
       "      <td>0.107063</td>\n",
       "      <td>0.117343</td>\n",
       "      <td>0.109096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999278</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>0.998777</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.999004</td>\n",
       "      <td>0.998988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689839</td>\n",
       "      <td>0.794522</td>\n",
       "      <td>0.727547</td>\n",
       "      <td>0.655012</td>\n",
       "      <td>0.772338</td>\n",
       "      <td>0.727852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255666</td>\n",
       "      <td>0.263397</td>\n",
       "      <td>0.251105</td>\n",
       "      <td>0.279102</td>\n",
       "      <td>0.286307</td>\n",
       "      <td>0.267115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5       sum\n",
       "0  0.0  0.000281  0.000371  0.000376  0.000351  0.000251  0.000326\n",
       "1  0.0  0.231833  0.201949  0.193909  0.186294  0.187436  0.200284\n",
       "2  0.0  0.109984  0.107898  0.103193  0.107063  0.117343  0.109096\n",
       "3  0.0  0.000133  0.000308  0.000197  0.000124  0.000201  0.000193\n",
       "4  0.0  0.007783  0.007487  0.009395  0.008523  0.008066  0.008251\n",
       "5  0.0  0.000567  0.000760  0.000791  0.000584  0.000418  0.000624\n",
       "6  0.0  0.999278  0.998631  0.998777  0.999252  0.999004  0.998988\n",
       "7  0.0  0.689839  0.794522  0.727547  0.655012  0.772338  0.727852\n",
       "8  0.0  0.255666  0.263397  0.251105  0.279102  0.286307  0.267115\n",
       "9  0.0  0.000376  0.000559  0.000431  0.000320  0.000413  0.000420"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
